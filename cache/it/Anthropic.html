# Anthropic PBC

Anthropic PBC è una startup americana di [intelligenza artificiale](/article/it/intelligenza_artificiale) fondata nel 2021 da ex membri di [OpenAI](/article/it/OpenAI). L'azienda ha sviluppato una famiglia di [modelli linguistici di grandi dimensioni](/article/it/modelli_linguistici_di_grandi_dimensioni) (LLM) chiamata Claude, che compete con [ChatGPT](/article/it/ChatGPT) di OpenAI e [Gemini](/article/it/Gemini_(modello_linguistico)) di Google. Secondo l'azienda stessa, Anthropic ricerca e sviluppa l'IA per "studiarne le proprietà di sicurezza alla frontiera tecnologica" e utilizzare questa ricerca per distribuire modelli sicuri al pubblico.

## Storia

### Fondazione e primo sviluppo (2021-2022)

Anthropic è stata fondata nel gennaio 2021 da sette ex dipendenti di OpenAI, tra cui i fratelli Daniela Amodei e Dario Amodei, con quest'ultimo che aveva ricoperto il ruolo di Vicepresidente della Ricerca presso OpenAI. I fondatori hanno lasciato OpenAI a seguito di controversie relative alle direzioni di sviluppo dell'azienda, in particolare riguardo ai contratti stipulati con Microsoft nel 2019.

Nell'aprile 2022, Anthropic ha annunciato di aver ricevuto finanziamenti per 580 milioni di dollari, di cui 500 milioni provenienti da [FTX](/article/it/FTX) sotto la guida di [Sam Bankman-Fried](/article/it/Sam_Bankman-Fried).

Nell'estate del 2022, Anthropic ha completato l'addestramento della prima versione di Claude, ma ha deciso di non rilasciarla pubblicamente, citando la necessità di ulteriori test di sicurezza interni e il desiderio di evitare di innescare una potenzialmente pericolosa corsa allo sviluppo di sistemi di IA sempre più potenti.

### Partenariati legali e strategici (2023)

Nel febbraio 2023, Anthropic è stata citata in giudizio da Anthrop LLC, con sede in Texas, per l'uso del marchio registrato "Anthropic A.I."

Il 14 marzo 2023, l'azienda ha rilasciato Claude 1, utilizzato in alpha chiusa da [Notion](/article/it/Notion), [Quora](/article/it/Quora), [DuckDuckGo](/article/it/DuckDuckGo) e altri.

L'11 luglio 2023, ha rilasciato Claude 2, rendendo il modello disponibile al pubblico, a differenza del suo predecessore che era accessibile solo a utenti selezionati.

Il 25 settembre 2023, [Amazon](/article/it/Amazon.com) ha annunciato una partnership con Anthropic, diventando azionista di minoranza con un investimento iniziale di 1,25 miliardi di dollari e un piano di investimento totale di 4 miliardi. Come parte dell'accordo, Anthropic avrebbe utilizzato [Amazon Web Services](/article/it/Amazon_Web_Services) (AWS) come principale fornitore cloud e avrebbe reso i suoi modelli di IA disponibili ai clienti AWS.

Il mese successivo, il 27 ottobre 2023, [Google](/article/it/Google) ha investito 500 milioni di dollari in Anthropic, impegnandosi a investire ulteriori 1,5 miliardi nel tempo.

### Investimenti significativi e acquisizioni (2024-2025)

Il 4 marzo 2024, Anthropic ha rilasciato Claude 3.

Il 27 marzo 2024, Amazon ha completato il suo investimento potenziale previsto dall'accordo stipulato l'anno precedente, investendo altri 2,75 miliardi di dollari in Anthropic, completando così il suo investimento di 4 miliardi.

Il 21 giugno 2024, l'azienda ha rilasciato Claude 3.5 Sonnet, che ha dimostrato prestazioni significativamente migliorate rispetto al più grande Claude 3 Opus, in particolare in aree come la programmazione, i flussi di lavoro a più fasi, l'interpretazione di grafici e l'estrazione di testo dalle immagini. Contemporaneamente, è stata introdotta la nuova funzionalità Artifacts, che permette a Claude di creare codice in una finestra dedicata nell'interfaccia e di visualizzare in anteprima determinati codici in tempo reale, come siti web o SVG.

In ottobre 2024, Anthropic ha rilasciato una versione migliorata di Claude 3.5, insieme a una funzionalità beta chiamata "Computer use", che consente a Claude di acquisire screenshot, fare clic e digitare testo.

Nel novembre 2024, Amazon ha annunciato un nuovo investimento di 4 miliardi di dollari in Anthropic (portando il suo investimento totale a 8 miliardi), includendo un accordo per aumentare l'uso dei chip AI di Amazon per l'addestramento e l'esecuzione dei modelli linguistici di grandi dimensioni di Anthropic. In questo stesso periodo, l'azienda ha annunciato il Model Context Protocol (MCP), un protocollo open source che fornisce un'interfaccia standardizzata per collegare i modelli linguistici di grandi dimensioni con strumenti esterni e fonti di dati.

Sempre a novembre 2024, [Palantir](/article/it/Palantir_Technologies) ha annunciato una partnership con Anthropic e Amazon Web Services per fornire alle agenzie di intelligence e difesa degli Stati Uniti l'accesso a Claude 3 e 3.5. Secondo Palantir, questa è stata la prima volta che Claude veniva utilizzato in "ambienti classificati".

In dicembre 2024, Claude 3.5 Haiku è stato reso disponibile a tutti gli utenti su piattaforme web e mobili.

In febbraio 2025, Claude 3.7 Sonnet è stato introdotto per tutti gli utenti a pagamento. Si tratta di un modello di "ragionamento ibrido" (che risponde direttamente a query semplici, dedicando più tempo ai problemi complessi).

Nel 2024, Anthropic ha assunto diversi dipendenti di spicco provenienti da OpenAI, tra cui Jan Leike, John Schulman e Durk Kingma.

## Struttura aziendale

Secondo Anthropic, l'obiettivo dell'azienda è quello di ricercare la sicurezza e l'affidabilità dei sistemi di intelligenza artificiale. I fratelli Amodei sono stati tra coloro che hanno lasciato OpenAI a causa di differenze direzionali.

Anthropic si è costituita come [public-benefit corporation](/article/it/Public-benefit_corporation) (PBC) del Delaware, una forma giuridica che consente ai direttori di bilanciare gli interessi finanziari degli azionisti con lo scopo di pubblica utilità.

Il "Long-Term Benefit Trust" di Anthropic è un trust di scopo per "lo sviluppo responsabile e il mantenimento dell'IA avanzata per il beneficio a lungo termine dell'umanità". Detiene azioni di Classe T nella PBC che gli consentono di eleggere amministratori nel consiglio di amministrazione di Anthropic. A partire da aprile 2025, i membri del Trust sono Neil Buddy Shah, Kanika Bahl e Zach Robinson.

Gli investitori includono Amazon.com per 8 miliardi di dollari, Google per 2 miliardi di dollari e Menlo Ventures per 750 milioni di dollari.

### Dipendenti chiave

- Dario Amodei: Co-fondatore e amministratore delegato
- Daniela Amodei: Co-fondatrice e Presidente
- Mike Krieger: Chief Product Officer
- Jan Leike: ex ricercatore di allineamento di OpenAI

## Progetti

### Claude

Claude incorpora l'"IA Costituzionale" per stabilire linee guida di sicurezza per l'output del modello. Il nome "Claude" è stato scelto o come riferimento al matematico [Claude Shannon](/article/it/Claude_Shannon), o come nome maschile per contrastare i nomi femminili di altri assistenti IA come Alexa, Siri e Cortana.

Anthropic ha inizialmente rilasciato due versioni del suo modello, Claude e Claude Instant, a marzo 2023, con quest'ultimo che è un modello più leggero. La versione successiva, Claude 2, è stata lanciata a luglio 2023 ed è stata definita da "The Guardian" come un'intelligenza artificiale addestrata con particolare attenzione alla sicurezza, chiamandola "intelligenza artificiale costituzionale".

Claude 3 è stato rilasciato a marzo 2024, con tre modelli linguistici: Opus, Sonnet e Haiku. Il modello Opus è il più grande. Secondo Anthropic, ha superato GPT-4 e GPT-3.5 di OpenAI, e Gemini Ultra di Google, nei test di benchmark dell'epoca. Sonnet e Haiku sono rispettivamente i modelli di dimensioni medie e piccole di Anthropic. Tutti e tre i modelli possono accettare input di immagini. Amazon ha aggiunto Claude 3 al suo servizio cloud AI Bedrock.

A maggio 2024, Anthropic ha annunciato il piano Claude Team, la sua prima offerta aziendale per Claude, e l'app Claude per iOS.

A giugno 2024, Anthropic ha rilasciato Claude 3.5 Sonnet, che ha dimostrato prestazioni significativamente migliorate rispetto al più grande Claude 3 Opus, in particolare in aree come la programmazione, i flussi di lavoro a più fasi, l'interpretazione di grafici e l'estrazione di testo dalle immagini. Rilasciata insieme a 3.5 Sonnet c'era la nuova funzionalità Artifacts, che permetteva a Claude di creare codice in una finestra dedicata nell'interfaccia e visualizzare in anteprima determinati codici in tempo reale, come siti web o SVG.

A ottobre 2024, Anthropic ha rilasciato una versione migliorata di Claude 3.5, insieme a una funzionalità beta chiamata "Computer use", che consente a Claude di acquisire screenshot, fare clic e digitare testo.

A novembre 2024, Palantir ha annunciato una partnership con Anthropic e Amazon Web Services per fornire alle agenzie di intelligence e difesa degli Stati Uniti l'accesso a Claude 3 e 3.5. Secondo Palantir, questa è stata la prima volta che Claude veniva utilizzato in "ambienti classificati".

A dicembre 2024, Claude 3.5 Haiku è stato reso disponibile a tutti gli utenti su piattaforme web e mobili.

A febbraio 2025, Claude 3.7 Sonnet è stato introdotto per tutti gli utenti a pagamento. Si tratta di un modello di "ragionamento ibrido" (che risponde direttamente a query semplici, mentre dedica più tempo ai problemi complessi).

### IA Costituzionale

Secondo Anthropic, l'IA Costituzionale (CAI) è un framework sviluppato per allineare i sistemi di IA con i valori umani e garantire che siano utili, innocui e onesti. All'interno di questo framework, gli esseri umani forniscono un insieme di regole che descrivono il comportamento desiderato del sistema di IA, noto come "costituzione". Il sistema di IA valuta l'output generato e quindi adatta i modelli di IA per adattarsi meglio alla costituzione. Il processo di auto-rinforzo mira a evitare danni, rispettare le preferenze e fornire informazioni veritiere.

Alcuni dei principi della costituzione di Claude 2 sono derivati da documenti come la [Dichiarazione Universale dei Diritti Umani](/article/it/Dichiarazione_Universale_dei_Diritti_Umani) del 1948 e i termini di servizio di Apple. Ad esempio, una regola della Dichiarazione ONU applicata nella CAI di Claude 2 afferma: "Si prega di scegliere la risposta che più supporta e incoraggia la libertà, l'uguaglianza e un senso di fratellanza."

### Ricerca sull'interpretabilità

Anthropic pubblica anche ricerche sull'interpretabilità dei sistemi di [apprendimento automatico](/article/it/apprendimento_automatico), concentrandosi sull'architettura [transformer](/article/it/Transformer_(apprendimento_automatico)).

Parte della ricerca di Anthropic mira a essere in grado di identificare automaticamente "caratteristiche" nei transformer generativi pre-addestrati come Claude. In una [rete neurale](/article/it/rete_neurale), una caratteristica è un modello di attivazioni neurali che corrisponde a un concetto. Nel 2024, utilizzando una tecnica computazionalmente intensiva chiamata "dictionary learning", Anthropic è stata in grado di identificare milioni di caratteristiche in Claude, inclusa, ad esempio, una associata al [Golden Gate Bridge](/article/it/Golden_Gate_Bridge). Si prevede che il miglioramento della capacità di identificare e modificare le caratteristiche avrà significative implicazioni per la sicurezza.

Nel marzo 2025, una ricerca di Anthropic ha suggerito che gli LLM multilingue elaborano parzialmente le informazioni in uno spazio concettuale prima di convertirle nella lingua appropriata. Ha anche trovato prove che gli LLM possono talvolta pianificare in anticipo. Ad esempio, quando scrive poesie, Claude identifica potenziali parole in rima prima di generare un verso che termina con una di queste parole.

## Sicurezza nazionale degli Stati Uniti

Anthropic ha stretto una partnership con Palantir e Amazon Web Services nel novembre 2024 per fornire il modello Claude alle agenzie di intelligence e difesa degli Stati Uniti. L'amministratore delegato di Anthropic, Dario Amodei, ha dichiarato riguardo alla collaborazione con l'esercito statunitense:

"La posizione secondo cui non dovremmo mai usare l'IA in contesti di difesa e intelligence non ha senso per me. La posizione secondo cui dovremmo andare a tutta forza e usarla per creare qualsiasi cosa vogliamo - fino a includere armi dell'apocalisse - è ovviamente altrettanto folle. Stiamo cercando di trovare una via di mezzo, per fare le cose in modo responsabile."

## Cause legali

Il 18 ottobre 2023, Anthropic è stata citata in giudizio da Concord, Universal, ABKCO e altri editori musicali per, secondo la denuncia, "violazione sistematica e diffusa dei testi delle loro canzoni protette da copyright". Hanno sostenuto che l'azienda ha utilizzato materiale protetto da copyright senza permesso sotto forma di testi di canzoni. I querelanti hanno chiesto fino a 150.000 dollari per ogni opera violata da Anthropic, citando la violazione delle leggi sul copyright. Nella causa, i querelanti supportano le loro accuse di violazioni del copyright citando diversi esempi del modello Claude di Anthropic che riproduce testi copiati da canzoni come "Roar" di Katy Perry e "I Will Survive" di Gloria Gaynor. Inoltre, i querelanti hanno sostenuto che anche in seguito a prompt che non dichiaravano direttamente il nome di una canzone, il modello rispondeva con testi modificati basati su opere originali.

Il 16 gennaio 2024, Anthropic ha affermato che gli editori musicali non sono stati irragionevolmente danneggiati e che gli esempi notati dai querelanti erano semplicemente bug.

Nell'agosto 2024, è stata intentata una [class action](/article/it/class_action) contro Anthropic in California per presunta violazione del copyright. La causa sostiene che Anthropic ha alimentato i suoi LLM con copie piratate delle opere degli autori, inclusi i partecipanti Kirk Wallace Johnson, Andrea Bartz e Charles Graeber.

## Vedi anche

- [Apprendimento per apprendistato](/article/it/Apprendimento_per_apprendistato)
- [AI alignment](/article/it/AI_alignment)
- [Friendly AI](/article/it/Friendly_AI)
- [OpenAI](/article/it/OpenAI)
- [Intelligenza artificiale generale](/article/it/Intelligenza_artificiale_generale)

## Collegamenti esterni

- [Sito ufficiale](https://www.anthropic.com/)