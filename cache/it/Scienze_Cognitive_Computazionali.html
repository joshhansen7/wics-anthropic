# Intelligenza Artificiale

L'**intelligenza artificiale** (in sigla italiana: IA o in inglese AI, dall'acronimo di Artificial Intelligence), nel suo significato più ampio, è la capacità o il tentativo di un sistema artificiale (tipicamente un sistema informatico o di automazione) di simulare una generica forma di intelligenza. Può essere definita come "l'intelligenza che le macchine o i software manifesterebbero, in contrasto con l'intelligenza degli esseri umani o degli animali" [af], o come "la scienza e l'ingegneria di costruire macchine intelligenti" [ar], secondo la definizione di John McCarthy, che coniò il termine nel 1955.

Lo standard ISO/IEC 42001:2023 Information technology - Artificial intelligence Management System (AIMS) ha definito l'intelligenza artificiale come «la capacità di un sistema di mostrare capacità umane quali il ragionamento, l'apprendimento, la pianificazione e la creatività» [it].

Più in dettaglio, Andreas Kaplan e Michael Haenlein definiscono l'intelligenza artificiale come "la capacità di un sistema di interpretare correttamente i dati esterni, di imparare da questi dati e di utilizzare tali apprendimenti per raggiungere obiettivi e compiti specifici attraverso un adattamento flessibile" [af].

Il concetto di "intelligenza artificiale", piuttosto ampio, viene spesso popolarmente (e banalmente) confuso con l'[intelligenza artificiale generativa](/article/it/intelligenza_artificiale_generativa), che è una specifica applicazione dell'intelligenza artificiale allo scopo di creare testi, immagini, audio, video o altri contenuti [it].

## Storia

### Dalle origini alle prime reti neurali artificiali

Esseri artificiali dotati di intelligenza sono apparsi nell'antichità come dispositivi narrativi, ed erano comuni nella narrativa, come nel [Frankenstein](/article/it/Frankenstein) di Mary Shelley o in [R.U.R.](/article/it/R.U.R.) di Karel Čapek. Questi personaggi e i loro destini hanno sollevato molte delle stesse questioni che ora vengono discusse nell'[etica dell'intelligenza artificiale](/article/it/etica_dell'intelligenza_artificiale) [af].

La nascita dell'intelligenza artificiale nel suo significato più ampio può essere fatta risalire all'avvento dei primi [computer](/article/it/computer) [it].

Nel 1936 [Alan Turing](/article/it/Alan_Turing) nel suo articolo "[On Computable Numbers, With An Application To The Entscheidungsproblem](/article/it/On_Computable_Numbers,_With_An_Application_To_The_Entscheidungsproblem)" discute su alcuni concetti che sono alla base del funzionamento dei computer e quindi dell'intelligenza artificiale, quali la calcolabilità, la computabilità e il concetto di [macchina di Turing](/article/it/macchina_di_Turing) [it]. Turing stava pensando all'intelligenza delle macchine almeno dal 1941, avendo diffuso un documento sull'intelligenza delle macchine che potrebbe essere stato il primo documento nel campo dell'IA - sebbene ora sia andato perduto [am].

Nel 1943 [McCulloch](/article/it/Warren_McCulloch) e [Pitts](/article/it/Walter_Pitts) crearono ciò che viene ritenuto il primo lavoro inerente all'intelligenza artificiale. Tale sistema impiega un modello di neuroni artificiali nel quale lo stato di tali neuroni può essere "acceso" o "spento," con un passaggio ad "acceso" in presenza di stimoli causati da un numero sufficiente di neuroni circostanti. McCulloch e Pitts dimostrarono che qualsiasi funzione computabile può essere rappresentata da qualche rete di neuroni, e che tutti i connettivi logici ("e", "o", ...) possono essere implementati da una semplice struttura neurale [it].

Nel 1950 [Marvin Minsky](/article/it/Marvin_Minsky) e Dean Edmonds, studenti dell'università di [Harvard](/article/it/Harvard), crearono la prima rete neurale artificiale, conosciuta con il nome di "SNARC" (Stochastic neural analog reinforcement calculator) [it].

### Il test di Turing

Nel 1950 Alan Turing, nel suo articolo "[Computing Machinery and Intelligence](/article/it/Computing_Machinery_and_Intelligence)", porta il dibattito filosofico a un livello più pragmatico, dando una definizione operativa di intelligenza basata su un test comportamentale inventato da lui stesso, chiamato "The Imitation Game" e ricordato anche come "[Test di Turing](/article/it/Test_di_Turing)" [ar].

Il test si basa sull'esistenza di tre stanze allineate in cui nella prima c'è un uomo e nell'ultima una donna; in quella centrale invece risiede l'interrogante. L'uomo e la donna possono comunicare messaggi di testo solamente con l'interrogatore scrivendo tramite una tastiera e leggendo tramite uno schermo. L'obiettivo della donna è quello di farsi identificare come donna, mentre quello dell'uomo è quello di trarre in inganno l'interrogante, facendogli credere di essere una donna.
Il gioco è ripetuto una seconda volta, scambiando l'uomo con una macchina.
La macchina è definita come intelligente se la frequenza con cui l'interrogante individua correttamente l'uomo e la donna è almeno la stessa con cui individua correttamente la macchina e la donna [it].

Essenzialmente, se un computer può ingannare qualcuno facendogli credere di essere un essere umano, il computer deve essere intelligente [af].

### La stanza cinese

In seguito, John Searle descrive nell'articolo "[Minds, Brains and Programs](/article/it/Minds,_Brains_and_Programs)" un esperimento mentale contro l'intelligenza artificiale forte, chiamato "[la stanza cinese](/article/it/stanza_cinese)". Egli vuole dimostrare che una macchina in grado di superare il test di Turing, non è capace di capire cosa succede al suo interno; non è, quindi, cosciente di come agisce [it].

L'esperimento consiste in una persona che conosce solo l'inglese, munita di un libro di grammatica cinese scritto in inglese e vari fogli, alcuni bianchi e alcuni con dei simboli. La persona è dentro alla stanza con una piccola finestra verso l'esterno. Attraverso la finestra appaiono simboli indecifrabili. La persona trova delle corrispondenze con i simboli del libro delle regole e segue le istruzioni. Le istruzioni possono includere scrivere simboli su un nuovo foglio, trovare nuovi simboli, ecc. Infine, questi fogli scritti verranno passati al mondo esterno, attraverso la finestra [it].

Per un osservatore esterno, la macchina sta ricevendo simboli cinesi, li sta elaborando e sta rispondendo con altri simboli, esattamente come farebbe un uomo cosciente. In questo senso, secondo il test di Turing dovrebbe essere ritenuta intelligente. Il problema, che sottolinea Searle, è che in realtà al suo interno, niente della macchina conosce effettivamente il cinese, per cui non è cosciente di quello che sta effettivamente facendo. Secondo Searle essa sta semplicemente seguendo un insieme di regole descritte nel libro [it].

Secondo [Daniel Dennett](/article/it/Daniel_Dennett) il dibattito rimane però aperto in quanto Searle non riesce a dimostrare pragmaticamente la sua tesi, dovendo far così ricorso alla intuizione [it].

### Conferenza di Dartmouth e nascita dell'IA

Nel 1956, nel [New Hampshire](/article/it/New_Hampshire), al [Dartmouth College](/article/it/Dartmouth_College), si tenne un convegno al quale presero parte [John McCarthy](/article/it/John_McCarthy), [Marvin Minsky](/article/it/Marvin_Minsky), [Claude Shannon](/article/it/Claude_Shannon) e Nathaniel Rochester. Su iniziativa di McCarthy, un team di dieci persone avrebbe dovuto creare in due mesi una macchina in grado di simulare ogni aspetto dell'apprendimento e dell'intelligenza umana. Ad aderire a tale iniziativa furono alcuni ricercatori, tra cui anche Trenchard More di [Princeton](/article/it/Princeton), Arthur Samuel di [IBM](/article/it/IBM), e Ray Solomonoff e Oliver Selfridge del [MIT](/article/it/MIT) [it].

Nello stesso convegno i ricercatori [Allen Newell](/article/it/Allen_Newell) e [Herbert Simon](/article/it/Herbert_Simon) presentarono un programma capace di qualche forma di ragionamento, conosciuto con il nome di "[Logic Theorist](/article/it/Logic_Theorist)", o LP, in grado di dimostrare teoremi partendo dai principi della matematica [it].

Sempre nello stesso convegno, McCarthy introdusse l'espressione "intelligenza artificiale" [it]. I partecipanti divennero i leader della ricerca sull'intelligenza artificiale per decenni [ar].

### Primi programmi di intelligenza artificiale

Il programma creato da Newell e Simon permise loro di progredire e creare un programma chiamato [General Problem Solver](/article/it/General_Problem_Solver), o GPS. A differenza del LP, il GPS fu ideato con lo scopo di imitare i processi di risoluzione dei problemi utilizzati dagli esseri umani (nello specifico la cosiddetta "[euristica mezzi-fini](/article/it/euristica_mezzi-fini)"). Nei ristretti casi nel quale il programma poteva operare, si notò che l'approccio con il quale il programma considerava gli obiettivi e le azioni era assimilabile a un umano. Negli stessi anni, presso l'IBM, Rochester con dei suoi colleghi cominciò a sviluppare altri programmi capaci di ragionamento [it].

Nel 1959, Herbert Gelemter creò il [Geometry Theorem Prover](/article/it/Geometry_Theorem_Prover), un programma in grado di dimostrare teoremi di geometria complessi [it].

L'anno precedente, presso il MIT, McCarthy definì il linguaggio di programmazione [Lisp](/article/it/Lisp), che venne utilizzato ampiamente per la realizzazione dei sistemi di intelligenza artificiale. McCarthy scrisse inoltre un documento intitolato [Programs with Common Sense](/article/it/Programs_with_Common_Sense), nel quale descrive un programma ideale, chiamato [Advice Taker](/article/it/Advice_Taker), che può essere visto come il primo sistema intelligente completo [it].

Minsky, durante il suo periodo al MIT, coordinò la creazione di programmi per affrontare quelli che vengono chiamati "micro mondi", ovvero problemi limitati e descritti da asserzioni che richiedevano l'utilizzo di ragionamento per essere risolti. Tra questi, il programma di James Slagle del 1963, SAINT, era in grado di risolvere problemi riguardo al calcolo integrale in forma chiusa. Alla fine degli anni '60 risale "[Gioco della vita](/article/it/Gioco_della_vita)", un automa cellulare sviluppato dal matematico inglese [John Conway](/article/it/John_Conway), che ha lo scopo di mostrare come comportamenti simili alla vita possano emergere da regole semplici e interazioni a molti corpi [it].

Tra le varie aspirazioni da parte dei ricercatori vi era principalmente quella di creare macchine in grado di esibire capacità di ragionamento simili a quelle umane. Ad esempio, Herbert Simon, nel 1957, stimò che nel giro di dieci anni ci sarebbero state macchine in grado di competere con i campioni di scacchi (previsione che si avvererà, ma dopo quarant'anni) [it].

### Primi successi e limiti

Queste aspirazioni, però, dovettero scontrarsi con alcune difficoltà: prime fra tutte, l'assoluta mancanza di conoscenza semantica relativa ai domini trattati dalle macchine, in quanto la loro capacità di ragionamento si limitava a una vera manipolazione sintattica. A causa di questa difficoltà, nel 1966 il governo degli [Stati Uniti d'America](/article/it/Stati_Uniti_d'America) interruppe i fondi per lo sviluppo delle macchine traduttrici [it].

Un ulteriore problema fu l'impossibilità del trattare molti problemi che l'intelligenza artificiale si era proposta. Questo perché si riteneva che "scalare" le dimensioni di un problema fosse solo una questione di hardware e memoria.
Questo tipo di ottimismo fu presto spento quando i ricercatori fallirono nel dimostrare teoremi a partire da più di una dozzina di assiomi. Si capì quindi che il fatto di disporre di un algoritmo che, a livello teorico, fosse in grado di trovare una soluzione a un problema non significava che un corrispondente programma fosse in grado di calcolarla effettivamente a livello pratico [it].

Un terzo tipo di difficoltà furono le limitazioni alla base della logica, nel senso di ragionamento, dei calcolatori. Nel documento di Minsky e Papert, intitolato [Perceptrons](/article/it/Perceptrons) (1969), si mostrò che, nonostante un percettrone (una semplice forma di rete neurale) fosse in grado di apprendere qualsiasi funzione potesse rappresentare, un percettrone con due input non era in grado di rappresentare una funzione che riconoscesse quando i due input sono diversi [it].

Le difficoltà degli anni precedenti portarono a definire gli approcci adottati dalle macchine come: "approcci deboli", che necessitavano quindi di una conoscenza maggiore inerente al campo di applicazione. Nel 1969, grazie a Ed Feigenbaum (studente di Herbert Simon), Bruce Buchanam e Joshua Lederberg, venne creato il programma [DENDRAL](/article/it/DENDRAL). Tale programma era in grado, a partire dalle informazioni sulla massa molecolare ricavate da uno spettrometro, di ricostruire la struttura di una molecola [it].

Questo programma fu quindi il primo dei sistemi basati su un uso intensivo della conoscenza, che arrivarono più tardi a inglobare tutti i concetti teorizzati da McCarthy per l'Advice Taker. Successivamente, Feigenbaum cominciò insieme con altri ricercatori di [Stanford](/article/it/Stanford) l'Heuristic Program Project (HPP), al fine di estendere gli scenari applicativi di questi sistemi, cominciando con il sistema [MYCIN](/article/it/MYCIN) nell'ambito delle diagnosi delle infezioni sanguigne. Si cominciò quindi a teorizzare dei sistemi conosciuti come "[sistemi esperti](/article/it/sistema_esperto)", ovvero in grado di possedere una conoscenza esperta in un determinato scenario di applicazione. Si trattava di sistemi in cui l'uomo trasferiva direttamente la propria conoscenza alla macchina, stabilendo mediante regole logiche quali fossero le scelte da prendere in determinati contesti [it].

### Le prime applicazioni industriali

Il primo sistema di intelligenza artificiale utilizzato in ambito commerciale fu [R1](/article/it/R1), utilizzato dalla Digital Equipment nel 1982. Lo scopo del programma era quello di aiutare a configurare gli ordini per nuovi computer. Nel 1986, fu in grado di far risparmiare alla compagnia 40 milioni di dollari all'anno. Anche la DuPont utilizzò sistemi simili, risparmiando circa dieci milioni di dollari all'anno. Negli anni '80 dello scorso secolo, quasi ogni grande azienda americana aveva un proprio sistema esperto in operazione e stava studiando sistemi più avanzati [it].

Nel 1981 in [Giappone](/article/it/Giappone) venne annunciato il progetto [Fifth Generation](/article/it/Fifth_Generation), un piano di dieci anni con l'intento di costruire sistemi intelligenti basati su [Prolog](/article/it/Prolog). In risposta, gli Stati Uniti d'America crearono la [Microelectronics and Computer Technology Corporation](/article/it/Microelectronics_and_Computer_Technology_Corporation) (MCC), come consorzio di ricerca al fine di garantire la competitività a livello nazionale. In [Inghilterra](/article/it/Inghilterra), il rapporto Alvey recuperò i fondi tagliati dal rapporto Lighthill, che nel 1973 portò il governo britannico alla decisione di interrompere il supporto verso la ricerca nell'ambito dell'intelligenza artificiale. Questi progetti però non raggiunsero gli scopi previsti [it].

L'industria dell'intelligenza artificiale raggiunse nel 1988 una cifra dell'ordine di miliardi di dollari, includendo centinaia di aziende che stavano creando sistemi esperti, robot e software e hardware specializzati in questi settori [it].

### Il ritorno delle reti neurali

A metà degli anni ottanta dello scorso secolo fu reinventato l'algoritmo di apprendimento per reti neurali chiamato [back-propagation](/article/it/back-propagation), inizialmente ideato nel 1969 da Bryson e Ho. L'algoritmo fu applicato a molti problemi relativi all'apprendimento, inerenti sia al lato dell'informatica sia a quello della psicologia [it].

I cosiddetti modelli "connessionisti" per la realizzazione di sistemi intelligenti furono visti come alternative ai modelli simbolici ideati da Newell e Simon, da McCarthy e dai loro collaboratori.
Tali modelli cercarono di dare risposta a quelle domande alle quali i precedenti modelli non erano riusciti, ma in parte fallirono anch'essi. Di conseguenza, i modelli basati sull'approccio simbolico e quelli con un approccio connessionista furono visti come complementari [it].

### I moderni progressi

Negli anni '90 e all'inizio del ventunesimo secolo, l'intelligenza artificiale ha ottenuto successi ancora maggiori, sebbene in gran parte dietro le quinte. L'intelligenza artificiale viene utilizzata nella logistica, nell'estrazione dei dati, nella diagnosi medica e in molti altri settori dell'industria tecnologica [ar].

Questo successo è dovuto a diversi fattori: la grande potenza dei computer odierni (vedi [legge di Moore](/article/it/legge_di_Moore)), una maggiore attenzione alla risoluzione di specifici sottoproblemi, la creazione di nuove relazioni tra il campo dell'intelligenza artificiale e altri campi che lavorano su problemi simili e, soprattutto, i ricercatori hanno iniziato ad adottare forti approcci matematici e rigorosi standard scientifici [ar].

L'[apprendimento profondo](/article/it/apprendimento_profondo) ha iniziato a dominare i benchmark industriali nel 2012 ed è stato adottato in tutto il campo. Per molte attività specifiche, altri metodi sono stati abbandonati. Il successo dell'apprendimento profondo è stato basato sia sui miglioramenti hardware (computer più veloci, unità di elaborazione grafica, cloud computing) che sull'accesso a grandi quantità di dati (compresi i set di dati raccolti come [ImageNet](/article/it/ImageNet)) [am].

Il successo dell'apprendimento profondo ha portato a un enorme aumento di interesse e finanziamenti nell'AI. È diventata la nuova tecnologia più produttiva in termini di numero di applicazioni di brevetti e brevetti concessi. Secondo 'AI Impacts', circa 50 miliardi di dollari all'anno sono stati spesi in "AI" intorno al 2022 solo negli Stati Uniti. Il 20% dei nuovi dottori di ricerca in informatica negli Stati Uniti si è specializzato in "AI". C'erano circa 800.000 offerte di lavoro "AI"-correlate negli Stati Uniti nel 2022. La maggior parte di questi sviluppi è avvenuta negli Stati Uniti, con aziende, università e laboratori di ricerca che guidano la ricerca sull'intelligenza artificiale [am].

Nel 2016, questioni di equità e uso improprio della tecnologia sono state spostate al centro della conferenza sull'apprendimento automatico, le pubblicazioni sono aumentate notevolmente, sono stati trovati finanziamenti e molti ricercatori hanno concentrato nuovamente la loro attenzione su questi problemi. Il problema dell'allineamento è diventato un campo di studio accademico serio [am].

## Concetti fondamentali

### Agente intelligente

Il concetto di agente intelligente (o agente razionale) è centrale in molti degli approcci più comuni all'intelligenza artificiale [it].

Un agente è un'entità in grado di percepire l'ambiente attraverso l'utilizzo di sensori e in grado di agire sull'ambiente attraverso l'utilizzo di attuatori. Ogni agente è quindi associato a una sequenza di percezioni, intesa come la cronologia completa di tutti i rilevamenti effettuati da ciascun sensore, e a una funzione agente, che specifica il comportamento dell'agente associando a ogni sequenza di percezioni un'azione da compiere [it].

È definita "misura della performance" una funzione che associa a ogni stato (o sequenza di stati) dell'ambiente un valore di utilità; un agente è intelligente (o razionale) se per ogni possibile sequenza di percezioni la sua funzione agente lo porta a compiere sempre l'azione che massimizza il valore atteso della misura della performance, data la sua conoscenza definita dalla sequenza di percezioni stessa e dalla conoscenza integrata nell'agente [it].

### Intelligenza artificiale forte e debole

Si distingue tra intelligenza artificiale debole e intelligenza artificiale forte o generale a seconda che vengano riprodotte o replicate solo alcune o tutte le funzionalità e capacità cognitive della mente umana [it]:

- L'**intelligenza artificiale debole** si specializza in compiti specifici, ed è l'unica attualmente in essere, paragonabile ad un mezzo e/o strumento per raggiungere un dato obbiettivo [it]. È definita anche come IA ristretta [ar].

- L'**intelligenza artificiale forte** ha come obbiettivo quello di raggiungere l'intelligenza generale ([AGI](/article/it/intelligenza_artificiale_generale) - Artificial General Intelligence) e quindi l'autocoscienza, ed è rivolta quindi ad un adattamento totale ad ogni situazione possibile, essa è ancora teorica [it]. Si definisce un'**Intelligenza Artificiale Superintelligente** (ASI – Artificial Superintelligence) un'Intelligenza Artificiale superiore alla forte, con capacità cognitive superiori a quelle dell'essere umano [it]. Il filosofo di Oxford [Nick Bostrom](/article/it/Nick_Bostrom) definisce la superintelligenza come "un intelletto molto più intelligente dei migliori cervelli umani in quasi ogni campo, inclusa la creatività scientifica, la saggezza generale e le abilità sociali" [ar].

### Rappresentazione della conoscenza

La rappresentazione della conoscenza e l'ingegneria della conoscenza costituiscono contributi centrali per la ricerca nell'ambito dell'intelligenza artificiale [it].

In particolare, queste discipline si focalizzano su quale tipo di conoscenza è necessario o opportuno integrare all'interno di un sistema intelligente, e sul come rappresentare i diversi tipi di informazione. Fra le cose che un sistema intelligente ha la necessità di rappresentare troviamo frequentemente oggetti, proprietà, categorie e relazioni fra oggetti, situazioni, eventi, stati, tempo, cause ed effetti, conoscenza posseduta da altri. La rappresentazione e l'ingegneria della conoscenza vengono spesso associate alla disciplina filosofica dell'[ontologia](/article/it/ontologia) [it].

La conoscenza e la sua rappresentazione sono cruciali soprattutto per quella categoria di sistemi intelligenti che basano il loro comportamento su una estensiva rappresentazione esplicita della conoscenza dell'ambiente in cui operano [it].

Tra i problemi più difficili nella rappresentazione della conoscenza ci sono:

#### Il Pensiero Predefinito e il Problema della Qualificazione
Gran parte di ciò che le persone sanno sono "presupposti". Ad esempio, quando si parla di uccelli in una conversazione, il cervello umano tipicamente crea l'immagine di un animale delle dimensioni di un pugno, che canta e vola. Ovviamente, non tutte queste caratteristiche si applicano a tutti gli uccelli. John McCarthy ha definito questo problema nel 1969 come il problema della qualificazione: per ogni regola logica che i ricercatori di intelligenza artificiale sono interessati a rappresentare, ci sono numerose eccezioni. Non c'è praticamente nulla che possa essere semplicemente dichiarato vero o falso in modo assoluto. La ricerca sull'intelligenza artificiale ha trovato diverse soluzioni a questo problema [ar].

#### L'Ampiezza della Conoscenza Logica
Una persona comune conosce un gran numero di fatti sull'esistenza. I progetti di ricerca che mirano a costruire una base completa di conoscenza logica (come [Cyc](/article/it/Cyc)) richiedono enormi quantità di ingegneria ontologica: devono essere costruiti in modo tradizionale dove concetti complessi vengono costruiti uno dopo l'altro. Uno degli obiettivi principali è che un computer comprenda abbastanza concetti da poter imparare leggendo fonti come Internet, e quindi sia in grado di aggiungere alla propria ontologia [ar].

#### La Forma Subsimbolica di Parte della Conoscenza Logica
Molte delle conoscenze delle persone non sono rappresentate come "fatti" o "dati" di cui si può parlare. Ad esempio, una persona esperta di scacchi evita una posizione perché la considera "esposta o insicura", e un critico d'arte riconosce un falso con uno sguardo. Queste sono intuizioni o tendenze rappresentate nel cervello in modo inconscio e subsimbolico. Tale conoscenza supporta e fornisce un contesto per la conoscenza simbolica cosciente [ar].

### Deduzione, ragionamento e problem solving

Inizialmente i ricercatori si concentrarono sullo sviluppo di algoritmi che imitassero fedelmente i ragionamenti impiegati dagli esseri umani per risolvere giochi o realizzare deduzioni logiche in modo da poterli integrare all'interno dei sistemi intelligenti [it].

Tali algoritmi solitamente si basano su una rappresentazione simbolica dello stato del mondo e cercano sequenze di azioni che raggiungano uno stato desiderato [it].

Con l'avanzare della ricerca, si è reso necessario affrontare problematiche più complesse, come l'incertezza e l'incompletezza delle informazioni disponibili. Di conseguenza, i ricercatori hanno integrato concetti provenienti da discipline come la probabilità, la statistica e l'economia. Ciò ha portato allo sviluppo di modelli probabilistici, reti bayesiane e tecniche di decision-making sotto incertezza, fondamentali per applicazioni moderne dell'intelligenza artificiale, come la pianificazione e la diagnosi [it].

L'aumento della disponibilità di dati ha spinto verso il [machine learning](/article/it/machine_learning) e il [deep learning](/article/it/deep_learning), che analizzano grandi dataset per trovare pattern e correlazioni. La gestione di questi dati richiede architetture distribuite, cloud computing e strumenti veloci ed efficienti [it].

Per difficoltà legate alla complessità intrinseca dei problemi in esame e delle dimensioni dei dataset, gli algoritmi di problem solving per la loro risoluzione possono a volte richiedere enormi risorse computazionali. L'ottimizzazione degli algoritmi ricopre una priorità assoluta all'interno della ricerca in questo ambito. Approcci come la ricerca euristica, la programmazione dinamica e l'uso di algoritmi evolutivi sono stati sviluppati per migliorare le prestazioni e ridurre il consumo di risorse [it].

### Pianificazione

Per permettere ai sistemi intelligenti di prevedere e rappresentare stati del mondo futuri e per prendere decisioni al fine di raggiungere tali stati massimizzando il valore atteso delle azioni, essi devono essere in grado di definire degli obiettivi e di perseguirli [it].

Nei problemi classici di pianificazione, un sistema intelligente può assumere di essere l'unica entità a operare nell'ambiente e può essere assolutamente sicuro delle conseguenze di ogni azione compiuta. Se non è l'unico attore nell'ambiente o se l'ambiente non è deterministico un sistema intelligente deve costantemente monitorare il risultato delle proprie azioni e aggiornare le predizioni future e i propri piani [it].

### Apprendimento automatico

L'[apprendimento automatico](/article/it/apprendimento_automatico) è la disciplina che studia algoritmi capaci di migliorare automaticamente le proprie prestazioni attraverso l'esperienza [it].

È stato un ambito di ricerca cruciale all'interno dell'intelligenza artificiale sin dalla sua nascita [it].

L'apprendimento automatico è particolarmente importante per lo sviluppo di sistemi intelligenti principalmente per tre motivi:

1. Gli sviluppatori di un sistema intelligente difficilmente possono prevedere tutte le possibili situazioni in cui il sistema stesso si può trovare a operare, eccetto per contesti estremamente semplici.
2. Gli sviluppatori di un sistema intelligente difficilmente possono prevedere tutti i possibili cambiamenti dell'ambiente nel tempo.
3. Un'ampia categoria di problemi può essere risolta più efficacemente ricorrendo a soluzioni che coinvolgono l'apprendimento automatico. Questa categoria di problemi include, ad esempio, il gioco degli [scacchi](/article/it/scacchi) e il riconoscimento degli oggetti [it].

Esistono diversi tipi di apprendimento automatico:

- **Apprendimento supervisionato**: Impara da dati etichettati [it]. Si divide in due tipi principali: classificazione (il programma deve imparare a prevedere in quale categoria rientra l'input) e regressione (il programma deve ridurre una funzione numerica basata su input numerici) [am].
- **Apprendimento non supervisionato**: Trova pattern nei dati non etichettati (es. clustering di clienti), a volte utilizzando il [data mining](/article/it/data_mining) [it]. Analizza flussi di dati e trova modelli e fa previsioni senza alcuna guida [am].
- **Apprendimento per rinforzo**: Impara tramite tentativi ed errori (es. [AlphaGo](/article/it/AlphaGo) di [DeepMind](/article/it/DeepMind)) [it]. L'agente viene premiato per le buone risposte e punito per quelle cattive. L'agente impara a scegliere risposte classificate come "buone" [am].
- **Apprendimento auto-supervisionato**: Un mix tra supervisionato e non supervisionato. Il modello impara a partire da dati che non sono etichettati esplicitamente, ma sfruttando una sorta di auto-etichettamento. Le varie previsioni di sviluppo dati servono quindi esse stesse come "supervisioni" nell'addestramento del modello. Non si ha bisogno di etichette esterne o annotazioni umane [it].
- **Trasferimento dell'apprendimento**: Avviene quando la conoscenza acquisita da un problema viene applicata a un nuovo problema [am].

Alcuni tipi di apprendimento possono avvenire in parallelo, dove due intelligenze artificiali con input diversi si confrontano tra loro "imparando" a vicenda [it].

### Elaborazione del linguaggio naturale

La capacità di elaborare il [linguaggio naturale](/article/it/linguaggio_naturale) fornisce ai modelli di intelligenza artificiale di stimare con ottime probabilità la parola o la frase che segue il testo fornito in input, e di estrarne il contesto. Questa tecnica consente di ottenere risultati migliori rispetto a tecniche tradizionali quando si tratta di svolgere ricerca di informazioni, ottenere risposta a domande, tradurre o analizzare testi. L'architettura tipicamente impiegata per questo compito è il [Transformer](/article/it/Transformer), che grazie al meccanismo dell'attenzione è in grado di catturare appieno il contesto del testo fornito in input [it].

La difficoltà principale di questo processo è l'intrinseca ambiguità che caratterizza i linguaggi naturali, per questo motivo le soluzioni richiedono un'estesa conoscenza del mondo e una notevole abilità nel manipolarlo [it].

Le moderne tecniche di apprendimento profondo per l'elaborazione del linguaggio naturale includono l'incorporamento di parole (rappresentazioni di parole che ne esprimono il significato, tipicamente come vettori), i trasformatori (un'architettura di apprendimento profondo che utilizza un meccanismo di attenzione) e altri. Nel 2019, i modelli linguistici [Generative Pre-trained Transformer](/article/it/Generative_Pre-trained_Transformer) (o "GPT") hanno iniziato a generare testo coerente, e nel 2023 questi modelli sono stati in grado di ottenere punteggi a livello umano negli esami di abilitazione, SAT, GRE e in molte altre applicazioni del mondo reale [am].

### Movimento e manipolazione

La [robotica](/article/it/robotica) è una disciplina strettamente correlata con l'intelligenza artificiale [it].

I robot possono essere considerati sistemi intelligenti per tutti quei compiti che richiedono capacità di livello cognitivo per la manipolazione o lo spostamento di oggetti e per la locomozione, con i sotto-problemi della localizzazione (determinare la propria posizione e quella di altre entità nello spazio), della costruzione di mappe (apprendere le caratteristiche dello spazio circostante), e della pianificazione ed esecuzione dei movimenti [it].

La robotica è strettamente importante per lo sviluppo di un AGI in quanto si vuole che l'intelligenza artificiale sia più "reale" e posso manipolare attivamente la realtà [it].

### Percezione

La percezione della macchina è la capacità di utilizzare gli input dai sensori (come telecamere, microfoni, segnali wireless, lidar attivo, sonar, radar e sensori tattili) per dedurre aspetti del mondo. La [visione artificiale](/article/it/visione_artificiale) è la capacità di analizzare gli input visivi [am].

Il campo include il riconoscimento vocale, la classificazione delle immagini, il riconoscimento facciale, il riconoscimento degli oggetti e la percezione robotica [am].

### Intelligenza sociale

Il calcolo affettivo è un ombrello interdisciplinare che comprende sistemi che riconoscono, interpretano, elaborano o simulano il sentimento, l'emozione e l'umore umano [am].

Alcuni assistenti virtuali, ad esempio, sono programmati per parlare in modo più socievole o anche per chiacchierare umoristicamente; questo li fa apparire più sensibili alla dinamica emotiva dell'interazione umana, o facilita altrimenti l'interazione uomo-computer [am].

Tuttavia, tende a dare agli utenti ingenui una concezione irrealistica di quanto siano realmente intelligenti gli agenti informatici esistenti [am].

### Intelligenza artificiale quantistica

Un filone di ricerca promettente tenta di applicare l'intelligenza artificiale alla potenza di calcolo dei computer e degli algoritmi quantistici [it].

In un Sistema quantistico le informazioni sono fisse ma esistono in uno stato di sovrapposizione fino a quando non vengono misurate, stessa cosa si può dire di un'sistema di intelligenza artificiale, dove invece del Qubit, si ha Bit a probabilità indotta, ha quindi un'comportamento emergente. Si sta andando a definire quindi un approccio sempre più rigoroso all' analisi logica. Emerge sempre più il concetto di discrezione delle gerarchie, o meglio di "livelli di visione dei sistemi complessi" e non solo una visione "filosofia" o "speculativa umana" [it].

## Classificazione dell'intelligenza artificiale

### Classificazione per approcci tecnici o tipi di funzionamento

Una distinzione dei tipi di intelligenza artificiale riguarda le tecniche con cui essa elabora i dati di input per produrre un certo tipo di output. Sono tecniche che possono esistere sia nell'intelligenza artificiale debole che in quella forte [it]. Si definiscono le seguenti categorie spesso correlate tra loro:

- **Intelligenza artificiale simbolica**: si basano su rappresentazioni "simboliche" di problemi, logica e ricerca (sono quindi "leggibili dall'uomo") [it].

- **Intelligenza artificiale discriminativa**: Il suo obiettivo è classificare o etichettare i dati di input. Classifica o distingue i diversi tipi di dati e traccia quindi i confini delle tracce dati (es "cane" diverso da "gatto") esempi sono modelli di classificazione come [BERT](/article/it/BERT) (per testi), [ResNet](/article/it/ResNet) (immagini), [EfficientNet](/article/it/EfficientNet), [Reti neurali convoluzionali](/article/it/Reti_neurali_convoluzionali), [Support Vector Machines](/article/it/Support_Vector_Machines) e i Modelli rilevamento frodi (es. rilevazione spam). Definisce quindi categorie in base a date caratteristiche di input [it].

- **Intelligenza artificiale generativa**: progettata per creare nuovi dati (immagini, testi, audio, video) partendo da input o contesti iniziali. I modelli generativi imparano le distribuzioni di probabilità dei dati di input e utilizzano questa conoscenza per creare contenuti nuovi che sembrano reali o plausibili. In fase di addestramento esse si basano su modelli discriminativi (impara a predire il prossimo token in base alla sua banca dati e discrimina quanto bene il modello sta generando output simili ai dati reali, discrimina buone o cattive predizioni). Una volta finito l'addestramento può entrare in una fase vera e propria generativa. Alcuni esempi sono: Modelli di linguaggio, [Stable Diffusion](/article/it/Stable_Diffusion), [DALL·E](/article/it/DALL·E) [it].

- **Intelligenza artificiale ibrida**: combina elementi di modelli generativi e discriminativi. Un esempio importante è rappresentato dalle [GAN](/article/it/GAN) dove due reti neurali (una generativa e una discriminativa) lavorano in parallelo, in un processo competitivo in cui il generatore cerca di creare dati realistici, mentre il discriminatore cerca di distinguere tra dati reali e creati. Un altro esempio sono i [VAE](/article/it/VAE) (Variational Autoencoders) modelli probabilistici che combinano aspetti generativi e discriminativi, es. interrogandosi e agendo sulla struttura dei dati in input [it].

- **Intelligenza artificiale predittiva**: prevede risultati basandosi su dati passati (modelli di forecasting, analisi predittiva) [it].

### L'architettura interna dei modelli

Un'altra classificazione tecnica dei tipi di intelligenza artificiale è quella basata sul tipo di architettura interna ai modelli [it]. Alcuni esempi sono:

- **Reti neurali (Deep Learning)**: Ispirate al cervello umano, usate per compiti complessi. In particolare nuove tecniche per migliorare l'efficienza e la specializzazione dei modelli stanno prendendo piede la più promettente è il [Mixture of Experts](/article/it/Mixture_of_Experts) (MoE) un'architettura avanzata di deep learning che suddivide i compiti tra diversi "esperti" specializzati. Invece di avere un'unica rete neurale che elabora tutti i dati, un modello MoE seleziona dinamicamente quali "esperti" devono attivarsi per rispondere a un dato input. Ogni esperto è una sottorete specializzata in un sottoinsieme del problema. Un router decide quale esperto attivare per ogni input, riducendo il numero di parametri effettivamente utilizzati in un dato momento. Questo approccio permette di scalare i modelli senza un aumento esponenziale della complessità computazionale, migliorando prestazioni e riducendo i costi. Esempio sono i modelli di linguaggio come [Google Switch Transformer](/article/it/Google_Switch_Transformer), che utilizza questa tecnica per gestire carichi di lavoro complessi con maggiore efficienza [it].

- **Alberi di decisione (Decision Tree)**: Struttura ad albero per decisioni sequenziali [it].

- **Macchine a vettori di supporto (SVM)**: Classificano dati separando le classi con iperpiani [it].

- **Reti bayesiane**: Modelli probabilistici che gestiscono l'incertezza [it].

## Differenze tra intelligenza naturale e intelligenza artificiale

La principale differenza tra l'intelligenza naturale (umana o animale) e l'intelligenza artificiale risiede nel fatto che l'intelligenza naturale è propria degli esseri viventi, mentre l'intelligenza artificiale è un prodotto dello sviluppo tecnologico [it].

Nei primi esempi di intelligenza artificiale le differenze con l'intelligenza umana erano piuttosto evidenti, ad esempio fornivano sempre lo stesso identico risultato in risposta ad una determinata "richiesta" o "domanda" dell'utente, evidenziando così la mancanza di adattività e creatività. Inoltre tali primi esempi di intelligenza artificiale necessitavano che le richieste dell'utente fossero fornite attraverso un'apposita interfaccia uomo-macchina (ad esempio una tastiera di un computer) utilizzando un linguaggio comprensibile al computer. Con il passare del tempo, i sistemi di intelligenza artificiale hanno acquisito caratteristiche che li rendono sempre più simili all'intelligenza umana o animale, ad esempio la capacità di identificare e simulare le espressioni facciali [it].

Sebbene l'intelligenza umana abbia alcune abilità, come ad esempio la capacità di provare emozioni e di adattarsi a molti cambiamenti del mondo esterno, che sono difficili (o impossibili) da eguagliare per un'intelligenza artificiale, per contro l'intelligenza artificiale ha manifestato, già nei suoi primi esempi, altre abilità superiori all'intelligenza umana, tra cui la velocità di risolvere espressioni matematiche [it].

Non possiamo affermare con certezza che le intelligenze artificiali che abbiamo sviluppato abbiano "un pensiero". Questo vale anche per gli altri esseri viventi (e non viventi) conosciuti, infatti non possiamo affermare con certezza che un delfino o un elefante siano capaci di fare discussioni filosofiche (nei loro pensieri o all'interno della loro comunità) [it].

## Approcci all'intelligenza artificiale

Non esiste una teoria unificata o un modello che guidi la ricerca sull'intelligenza artificiale. I ricercatori hanno divergenze su molte questioni. Una delle questioni rimaste irrisolte per lungo tempo è: l'intelligenza artificiale dovrebbe simulare l'intelligenza naturale studiando la psicologia o le neuroscienze? O la biologia umana è irrilevante per la ricerca sull'intelligenza artificiale come la biologia degli uccelli lo è per l'ingegneria aeronautica? Il comportamento intelligente può essere descritto usando principi semplici ed eleganti (come la logica o l'ottimizzazione)? O richiede necessariamente la risoluzione di un gran numero di problemi non correlati tra loro? L'intelligenza può essere riprodotta usando simboli di alto livello, simili a parole e idee? O richiede un'elaborazione "subsimbolica"? [ar]

### Cibernetica e Simulazione del Cervello

Negli anni '40 e '50, un certo numero di ricercatori ha esplorato la relazione tra neuroscienze, teoria dell'informazione e cibernetica. Alcuni hanno costruito macchine che utilizzavano reti elettroniche per mostrare un'intelligenza primitiva, come le tartarughe di W. Grey Walter e il Bestiolino di Johns Hopkins. Molti di questi ricercatori si riunirono per partecipare agli incontri della Società Teleologica all'Università di Princeton e del Club di Ratio in Inghilterra. Entro il 1960, questo approccio era in gran parte abbandonato, sebbene alcuni elementi siano tornati in vita negli anni '80 [ar].

### Intelligenza Artificiale Simbolica Tradizionale

Con l'arrivo dei computer digitali a metà degli anni '50, la ricerca sull'intelligenza artificiale iniziò a esplorare la possibilità che l'intelligenza umana potesse essere ridotta alla manipolazione di simboli. La ricerca si concentrò in tre istituzioni: CMU, Stanford e MIT, ognuna delle quali sviluppò il proprio stile di ricerca. John Haugeland chiamò questi approcci all'intelligenza artificiale "Good Old-Fashioned Artificial Intelligence" o "GOFAI" [ar].

#### Simulazione Cognitiva

Gli economisti Herbert Simon e Allen Newell studiarono le abilità umane e cercarono di formalizzarle. Con il loro lavoro, gettarono le basi dell'intelligenza artificiale, oltre che delle scienze cognitive, della ricerca operativa e delle scienze manageriali. Il loro team di ricerca condusse esperimenti psicologici per dimostrare le somiglianze tra le abilità umane di risoluzione dei problemi e quelle dei programmi che stavano progettando (come il "General Problem Solver"). Questa tradizione, centrata alla Carnegie Mellon University, avrebbe alla fine portato allo sviluppo dell'architettura cognitiva Soar a metà degli anni '80 [ar].

#### Intelligenza Artificiale Logica

A differenza di Newell e Simon, John McCarthy riteneva che le macchine non avessero bisogno di simulare il pensiero umano, ma piuttosto di cercare l'essenza della logica astratta e della risoluzione dei problemi, indipendentemente dal fatto che le persone utilizzassero gli stessi algoritmi. Al suo laboratorio di Stanford (SAIL), si concentrò sull'uso della logica per risolvere un'ampia gamma di problemi, inclusa la rappresentazione della conoscenza, la pianificazione automatica, la programmazione e l'apprendimento automatico. La logica era anche al centro del lavoro all'Università di Edimburgo e in altri luoghi in Europa, che portò allo sviluppo del linguaggio di programmazione Prolog e della programmazione logica [ar].

#### Intelligenza Artificiale Simbolica "Scribblata"

I ricercatori del MIT (come Marvin Minsky e Seymour Papert) scoprirono che la risoluzione di problemi difficili nella visione e nell'elaborazione del linguaggio naturale richiedeva soluzioni ad hoc—e affermarono che non esiste un principio generale e semplice (come la logica) che possa comprendere tutti gli aspetti del comportamento intelligente. Roger Schank descrisse i loro approcci "anti-logici" come "scribblati" (in contrasto con i modelli "puliti" della Carnegie Mellon University e di Stanford). Le basi di conoscenza logica (come il progetto Cyc di Doug Lenat) sono un esempio di intelligenza artificiale "scribblata", poiché devono essere progettate manualmente, un concetto complesso dopo l'altro [ar].

### Intelligenza Artificiale Basata sulla Conoscenza

Quando grandi memorie per computer divennero disponibili intorno al 1970, i ricercatori di tutte e tre queste tradizioni iniziarono a costruire conoscenza nelle applicazioni di intelligenza artificiale. Questa "rivoluzione della conoscenza" portò allo sviluppo e alla diffusione dei sistemi esperti (introdotti da Edward Feigenbaum), che furono la prima forma veramente riuscita di software di intelligenza artificiale. La rivoluzione della conoscenza fu anche guidata dalla consapevolezza che enormi quantità di conoscenza sarebbero state necessarie per molte semplici applicazioni di intelligenza artificiale [ar].

### Intelligenza Artificiale Subsimbolica

Durante gli anni '60, gli approcci simbolici ebbero grande successo nel simulare il pensiero di alto livello in piccoli programmi dimostrativi. Gli approcci basati sulla cibernetica o sulle reti neurali furono abbandonati o relegati in secondo piano.
Negli anni '80, tuttavia, i progressi nell'intelligenza artificiale simbolica si arrestarono, e molti credevano che i sistemi simbolici non sarebbero stati in grado di simulare tutti i processi cognitivi umani, in particolare la percezione, la robotica, l'apprendimento e il riconoscimento di modelli. Un certo numero di ricercatori iniziò a guardare ad approcci "subsimbolici" per problemi specifici dell'intelligenza artificiale [ar].

### Intelligenza Artificiale Bottom-up, Embedded, Situated, Behavior-based o Nuova IA

I ricercatori nel campo della robotica, come Rodney Brooks, rifiutarono l'intelligenza artificiale simbolica e si concentrarono sui problemi ingegneristici di base che avrebbero permesso ai robot di muoversi e sopravvivere. Il loro lavoro fece rivivere il punto di vista non simbolico dei primi ricercatori di cibernetica degli anni '50 e reintrodusse la teoria del controllo nell'intelligenza artificiale. Questi approcci sono teoricamente collegati alla tesi della mente incarnata [ar].

### Intelligenza Computazionale

L'interesse rinnovato per le reti neurali e il "connessionismo" fu stimolato da David Rumelhart e altri a metà degli anni '80. Ora questi approcci e altri metodi subsimbolici, come i sistemi fuzzy e i calcoli evolutivi, vengono studiati collettivamente sotto il campo emergente dell'intelligenza computazionale [ar].

### Intelligenza Artificiale Statistica

Negli anni '90, i ricercatori di intelligenza artificiale svilupparono strumenti matematici sofisticati per risolvere specifici sottoproblemi. Questi strumenti sono veramente scientifici, nel senso che i loro risultati sono sia misurabili che verificabili, e sono stati responsabili di molti dei recenti successi della ricerca sull'intelligenza artificiale. Questi strumenti matematici consentono anche un alto livello di collaborazione con più campi (come matematica, economia o ricerca operativa). Stuart Russell e Peter Norvig hanno descritto questo movimento come niente meno che una "rivoluzione" e un "trionfo dei sistematici" [ar].

### Integrazione di Approcci

#### Il Modello dell'Agente Intelligente

Un agente intelligente è un sistema che percepisce il suo ambiente e intraprende azioni che aumentano le sue possibilità di successo. Gli agenti intelligenti nella loro forma più semplice sono programmi per risolvere problemi specifici. I più complessi sono gli esseri umani pensanti e razionali. Questo modello dà ai ricercatori la licenza di studiare problemi individuali e trovare soluzioni che possono essere verificate e utilizzate, senza concordare un unico approccio. Un agente può utilizzare qualsiasi approccio adatto per risolvere un problema specifico—alcuni agenti sono simbolici e logici, altri sono reti neurali subsimboliche, e altri ancora possono utilizzare nuovi approcci. Il modello fornisce anche ai ricercatori un linguaggio comune per comunicare con altri campi, come la teoria delle decisioni e l'economia, che utilizzano anch'essi concetti di agenti astratti. Il modello dell'agente intelligente è diventato ampiamente accettato negli anni '90 [ar].

#### Agente Strutturato [o] Cognizione Strutturata

I ricercatori hanno progettato sistemi per costruire sistemi intelligenti attraverso l'interazione di agenti intelligenti in un sistema multi-agente. Un sistema composto da componenti simbolici e subsimbolici è un sistema intelligente ibrido, e lo studio di tali sistemi è considerato un'integrazione di sistemi di intelligenza artificiale. Un sistema di monitoraggio gerarchico fornisce un ponte tra l'intelligenza artificiale subsimbolica alla base della piramide e i livelli reattivi e l'intelligenza artificiale simbolica tradizionale in cima alla piramide, dove la distanza temporale consente la pianificazione e la modellazione del mondo. La struttura della sussunzione di Rodney Brooks fu una proposta precoce per questo sistema gerarchico [ar].

## Strumenti per la ricerca sull'intelligenza artificiale

Durante cinquant'anni di ricerca, l'intelligenza artificiale ha sviluppato un gran numero di strumenti per risolvere i problemi più difficili dell'informatica [ar].

### Ricerca e Ottimizzazione

Molti problemi di intelligenza artificiale possono essere teoricamente risolti con una ricerca intelligente tra molte soluzioni possibili: il ragionamento logico può essere ridotto a una ricerca. Ad esempio, il ragionamento logico può essere considerato come una ricerca di un percorso che parte da presupposti e arriva a conclusioni, dove ogni passo è l'applicazione di una regola di inferenza [ar].

Gli algoritmi di pianificazione cercano attraverso alberi di obiettivi e sottoobiettivi, tentando di trovare un percorso verso l'obiettivo, un processo chiamato analisi mezzi-fini [ar].

Gli algoritmi robotici utilizzano motori di ricerca locali per muovere arti e afferrare oggetti nello spazio delle configurazioni [ar].

Molti algoritmi di apprendimento utilizzano algoritmi di ricerca basati sull'ottimizzazione [ar].

Le semplici ricerche esaustive raramente sono sufficienti per la maggior parte dei problemi del mondo reale: lo spazio di ricerca (il numero di luoghi in cui cercare) cresce rapidamente fino a raggiungere numeri astronomici. Il risultato è una ricerca estremamente lenta o una ricerca che non termina mai. La soluzione per molti problemi è utilizzare "euristiche" o "regole empiriche" che eliminano le scelte improbabili (chiamate "potatura dell'albero di ricerca"). L'euristica fornisce al programma la "migliore ipotesi" per una soluzione [ar].

Un tipo molto diverso di ricerca è emerso negli anni '90, basato sulla teoria matematica dell'ottimizzazione. Per molti problemi, è possibile iniziare con qualche tipo di congettura e poi modificare gradualmente la congettura fino a raggiungere un punto ottimale dove non è possibile fare ulteriori miglioramenti. Questi algoritmi possono essere visualizzati come un cieco che sale su una collina: la ricerca inizia in un punto casuale, e poi, dopo alcuni salti o passi, continua a muovere l'ipotesi salendo sulla collina fino a raggiungere la cima. Altri algoritmi di ottimizzazione includono: simulated annealing, beam search e random optimization [ar].

Il calcolo evolutivo utilizza una forma di ricerca ottimale. Ad esempio, potrebbe iniziare con una popolazione di "ipotesi", poi permettere loro di mutare e ricombinarsi, selezionando solo le più adatte per sopravvivere in ogni generazione (raffinando le ipotesi). Le forme di calcolo evolutivo includono algoritmi di intelligenza di sciame (come l'ottimizzazione delle colonie di formiche o delle particelle) e algoritmi evolutivi (come gli algoritmi genetici) e la programmazione genetica [ar].

### Logica

La logica fu introdotta nel campo della ricerca sull'intelligenza artificiale da John McCarthy nel 1958 attraverso la sua proposta "Advice Taker". Nel 1963, J. Alan Robinson scoprì un semplice e completo algoritmo per l'inferenza logica che poteva essere facilmente eseguito dai computer digitali [ar].

Tuttavia, l'implementazione ingenua degli algoritmi porta rapidamente a un'esplosione combinatoria o a un ciclo infinito. Nel 1974, Robert Kowalski propose di rappresentare le espressioni logiche in termini di clausole di Horn (affermazioni in forma di regole, come "a è vero se b è vero"), riducendo l'inferenza logica a un concatenamento all'indietro o in avanti. Questo alleviò notevolmente il problema (ma non lo eliminò) [ar].

La logica viene utilizzata per rappresentare la conoscenza e risolvere problemi, ma può essere applicata anche ad altri problemi. Ad esempio, l'algoritmo SATPLAN utilizza la logica per la pianificazione, e la programmazione logica induttiva è un metodo per l'apprendimento [ar].

Ci sono diverse forme di logica utilizzate nella ricerca sull'intelligenza artificiale:

- **Logica proposizionale o booleana**: è la logica delle affermazioni che possono essere vere o false [ar].
- **Logica del primo ordine**: consente anche l'uso di quantificatori e predicati, e può esprimere fatti sugli oggetti, le loro proprietà e le relazioni tra di loro [ar].
- **Logica fuzzy**: è un tipo di logica del primo ordine che permette di rappresentare la verità di un'affermazione con un valore tra 0 e 1, invece di semplicemente (1) per vero o (0) per falso. Il sistema fuzzy può essere utilizzato per il ragionamento incerto ed è stato ampiamente utilizzato nei moderni sistemi di controllo industriale e nei prodotti di consumo [ar].
- **Logica di default, logica non monotona e circonscritta**: sono forme di logica progettate per aiutare con il pensiero predefinito e il problema della qualificazione [ar].

Diverse estensioni della logica sono state progettate per trattare domini specifici di conoscenza, come: logica descrittiva; calcolo situazionale, calcolo degli eventi e calcolo dei fluenti (per rappresentare eventi e tempo); calcolo causale; calcolo delle credenze e logica probabilistica [ar].

### Metodi Probabilistici per il Ragionamento Incerto

Molti problemi nella ricerca sull'intelligenza artificiale (nel ragionamento, pianificazione, apprendimento, comprensione e robotica) richiedono che un agente operi con informazioni incomplete o incerte. A partire dalla fine degli anni '80 e dai primi anni '90, Judea Pearl e altri hanno sostenuto l'uso di metodi derivati dalla teoria della probabilità e dall'economia per sviluppare una serie di potenti strumenti per risolvere questi problemi [ar].

Le reti bayesiane sono uno strumento molto generale che può essere utilizzato in un gran numero di problemi: ragionamento (utilizzando l'algoritmo di inferenza bayesiana), apprendimento (utilizzando l'algoritmo di massima aspettativa), pianificazione (utilizzando le reti di decisione) e percezione (utilizzando le reti bayesiane dinamiche) [ar].

Gli algoritmi probabilistici possono anche essere utilizzati per filtrare, prevedere, smussare e trovare spiegazioni per flussi di dati, e aiutare i sistemi di percezione ad analizzare i processi che si verificano nel tempo (ad esempio, modelli di Markov nascosti o filtri di Kalman) [ar].

Un concetto chiave dell'economia è l'"utilità": una misura del valore di qualcosa per un agente intelligente. Sono stati sviluppati strumenti matematici precisi per analizzare come un agente può fare scelte e piani, utilizzando la teoria delle decisioni, l'analisi decisionale e la teoria del valore dell'informazione [ar].

Questi strumenti includono modelli come i processi decisionali di Markov, le reti di decisione dinamiche, la teoria dei giochi e la progettazione dei meccanismi [ar].

### Classificatori e Metodi di Apprendimento Statistico

Le applicazioni più semplici dell'intelligenza artificiale possono essere divise in due tipi: classificatori ("se è brillante allora è un diamante") e controllori ("se è brillante, prendilo"). Tuttavia, i controllori classificano le condizioni prima di dedurre azioni, quindi i tipi di classificazione formano una parte fondamentale di molti sistemi di intelligenza artificiale [ar].

I classificatori sono compiti che utilizzano la corrispondenza di pattern per determinare la corrispondenza più vicina. Possono essere sintonizzati secondo modelli ed essere molto attraenti da utilizzare nell'intelligenza artificiale. Questi esempi sono noti come osservazioni o pattern. Nell'apprendimento supervisionato, ogni pattern appartiene a una classe predefinita. Queste classi possono essere considerate come decisioni da prendere. Tutte le osservazioni con le loro etichette di classe sono note come set di dati [ar].

Quando viene presentata una nuova osservazione, questa viene classificata in base all'esperienza precedente. I classificatori possono essere addestrati in vari modi, ci sono molti approcci statistici e di apprendimento automatico [ar].

È disponibile un'ampia gamma di classificatori, ognuno con i suoi punti di forza e di debolezza. Le prestazioni del classificatore dipendono fortemente dalle caratteristiche dei dati da classificare. Non esiste un classificatore che funzioni meglio per tutti i problemi, ciò che viene definito come il teorema "no free lunch". Sono stati condotti vari test empirici per confrontare le prestazioni dei classificatori e trovare le caratteristiche dei dati che determinano le prestazioni di classificazione. Tuttavia, determinare il classificatore appropriato per un problema specifico è considerato più un'arte che una scienza [ar].

I classificatori più utilizzati sono le reti neurali, i metodi kernel come le macchine a vettori di supporto, l'algoritmo k-nearest neighbor, il modello di miscela gaussiana, il classificatore bayesiano naive e gli alberi di decisione. Le prestazioni di questi classificatori sono state confrontate su molti compiti di classificazione per arrivare alle caratteristiche dei dati che determinano le prestazioni di classificazione [ar].

### Reti Neurali

Lo studio delle reti neurali artificiali iniziò nel decennio precedente la fondazione della ricerca sull'intelligenza artificiale. Negli anni '60, Frank Rosenblatt sviluppò una versione importante e nuova; vale a dire, il percettrone [ar].

Paul Werbos sviluppò l'algoritmo di backpropagation per i percettroni multistrato nel 1974, portando a una rinascita nel campo della ricerca sulle reti neurali e sul "connessionismo" in generale a metà degli anni '80. La rete di Hopfield, una forma di rete attrattore, fu descritta per la prima volta da John Hopfield nel 1982 [ar].

Tra le architetture di rete sviluppate ci sono la rete feedforward, la rete a base radiale, la mappa auto-organizzante di Kohonen e varie reti neurali ricorrenti. Le reti neurali vengono applicate al problema dell'apprendimento, utilizzando tecniche come l'apprendimento hebbiano, l'apprendimento competitivo [ar].

I design relativamente nuovi includono la gerarchia di memoria temporale e le reti di credenza profonda [ar].

### Teoria del Controllo

La teoria del controllo, nata dalla cibernetica, ha molte importanti applicazioni, specialmente nella robotica [ar].

### Linguaggi Specializzati

I ricercatori di intelligenza artificiale hanno sviluppato molti linguaggi specializzati per la ricerca sull'intelligenza artificiale [ar]:

- **IPL**: è stato il primo linguaggio progettato per applicazioni di intelligenza artificiale. Include caratteristiche che supportano programmi per risolvere problemi generali, comprese liste, concetti collegati tra loro, schemi (frame), allocazione dinamica della memoria, tipi di dati, chiamate ricorsive, recupero associativo, funzioni come valori, generatori (stream) ed esecuzione simultanea di compiti [ar].

- **Lisp**: è un sistema pratico di calcolo per programmi per computer basato sul calcolo lambda. Le liste collegate sono una delle principali strutture di dati dei linguaggi Lisp, e il codice sorgente Lisp stesso è composto da liste. Di conseguenza, i programmi Lisp possono modificare il codice sorgente come strutture di dati, il che ha portato a sistemi complessi che consentono ai programmatori di creare nuove strutture o linguaggi di programmazione specializzati incorporati in Lisp. Oggi esistono molti dialetti di Lisp [ar].

- **Prolog**: è un linguaggio dichiarativo che esprime i programmi attraverso relazioni, e l'esecuzione avviene eseguendo query su queste relazioni. Prolog è particolarmente utile per il ragionamento logico simbolico, le applicazioni di database e l'analisi. È ampiamente utilizzato oggi nell'intelligenza artificiale [ar].

- **STRIPS**: è un linguaggio per esprimere problemi di pianificazione automatica. Esprime lo stato iniziale, le condizioni dell'obiettivo e un insieme di azioni. Ogni azione ha precondizioni (ciò che deve essere vero prima che l'azione possa essere eseguita) e postcondizioni (ciò che è vero dopo che l'azione è stata eseguita) [ar].

- **Planner**: è una combinazione di linguaggi procedurali e logici. Dà un'interpretazione procedurale semplificata alle affermazioni logiche a differenza della semantica che interpreta attraverso l'inferenza formale [ar].

Le applicazioni di intelligenza artificiale sono spesso scritte anche in linguaggi standard come C++ e linguaggi progettati per la matematica come MATLAB e Lush [ar].

## Applicazioni

L'intelligenza artificiale è stata impiegata in un'ampia varietà di campi e applicazioni come la medicina, il mercato azionario, la robotica, la legge, la ricerca scientifica, l'analisi dei dati, i giocattoli e perfino lo sviluppo di nuovi robot usando la potenza di calcolo di un personal computer. In alcune applicazioni, l'intelligenza artificiale si è radicata a tal punto all'interno della società o dell'industria da non essere più percepita come intelligenza artificiale. Essa trova applicazione anche nelle città intelligenti: gestione dei flussi (veicolari o turistici), operatività delle reti (telecomunicazioni ed energia), acquisti online e telelavoro. Inoltre, trova applicazione nell'e-procurement, ad esempio nella ricerca e selezione di nuovi fornitori [it].

Oggigiorno i sistemi intelligenti sono presenti in ogni campo, anche nelle attività quotidiane e primeggiano nei giochi, come teorizzato anni prima dagli esponenti dell'intelligenza artificiale [it].

Vi sono programmi che sono stati in grado di confrontarsi con campioni di scacchi, quali [Deep Blue](/article/it/Deep_Blue); altri che sono stati impiegati nelle missioni spaziali, come nel 1998 quando la [NASA](/article/it/NASA) utilizzò un programma chiamato [Remote Agent](/article/it/Remote_Agent) in grado di gestire le attività relative a un sistema spaziale; alcune auto sono oggi dotate di un sistema in grado di guidarle senza l'uso di un conducente umano, quindi in maniera del tutto autonoma [it].

Nell'ambito di scenari più quotidiani si pensi, invece, ai termostati per il riscaldamento e l'aria condizionata in grado di anticipare il cambio di temperatura, gestire i bisogni degli abitanti e di interagire con altri dispositivi [it].

Esempi di applicazioni dell'intelligenza artificiale sono:

### Intelligenza artificiale applicata alla ricerca
La necessità di raccogliere ed elaborare grandi moli di dati ed informazioni [it].

### Intelligenza artificiale applicata all'informatica
Nel campo dell'informatica stessa, molte soluzioni sviluppate originariamente per rispondere a problemi o necessità dell'intelligenza artificiale sono state adottate da altre discipline e non vengono più considerate parte dell'intelligenza artificiale. In particolare il time-sharing, l'interprete (informatica), l'interfaccia grafica, il mouse, la struttura dati lista concatenata, la programmazione funzionale, la programmazione simbolica, la programmazione dinamica e la programmazione orientata agli oggetti [it].

### Intelligenza artificiale applicata alla finanza
Previsioni di mercato (intelligenza artificiale per il trading), rilevamento frodi. Il primo utilizzo dell'intelligenza artificiale nelle banche è datato 1987 quando la Security Pacific National Bank negli USA organizzò una task force per la prevenzione delle frodi legate all'utilizzo non autorizzato delle carte di credito. Attualmente, e non solo in ambito bancario, le reti neurali vengono utilizzate per identificare fenomeni non riconducibili a un comportamento nominale e che richiedono un intervento umano [it].

### Intelligenza artificiale applicata alla medicina
Diagnosi, predizione di malattie ([DeepMind Health](/article/it/DeepMind_Health)). Infatti la spesa per l'intelligenza artificiale in ambito sanitario è raddoppiata nel 2020 fino a quota 4.8 miliardi di dollari, e, nuovamente nel 2021, a 10 miliardi di dollari. Le reti neurali sono oggi largamente impiegate in medicina, e ancora molte altre applicazioni sono attualmente in sviluppo, come ad esempio [it]:

- Interpretazione delle immagini mediche: ad esempio, valutazione della posizione, estensione e gravità di un ictus cerebrale; analisi dell'elettrocardiogramma per la valutazione del rischio di infarto miocardico acuto; analisi dell'angiografia e dell'imaging intravascolare per la prevenzione della malattia aterosclerotica coronarica
- Analisi del suono del cuore, previsione di eventi cardiaci avversi nelle due settimane successive a un impianto di stent
- monitoraggio della terapia intensiva e riduzione del rischio di morte
- Diagnosi del cancro e delle malattie in genere mediante un'analisi multimodale dei sintomi
- Diagnosi della leucemia
- gestione dell'ematologia
- medicina del sonno, diagnosi del disturbo unipolare e bipolare, depressione, psicoradiologia, progressione della malattia di Parkinson
- Creazione di medicine
- Robot di accompagnamento per gli anziani, cura della persona e assistenza quotidiana: monitoraggio dei parametri vitali, monitoraggio dell'assunzione quotidiana dei farmaci prescritti, azioni tese a rimanere connessi col mondo esterno e in contatto con parenti amici e a svolgere una vita attiva, anche attraverso l'uso di app di videochiamata e di messaggistica istantanea, assistenza cognitiva e inclusione digitale, rilevazione delle cadute

Nel campo della ricerca medica, l'AI è uno strumento essenziale per elaborare e sintetizzare grandi quantità di dati. È particolarmente cruciale per lo sviluppo di organoidi e ingegneria tissutale, dove utilizzano l'imaging microscopico come tecnica chiave nel processo creativo. È stato suggerito che l'AI potrebbe superare le disparità di finanziamento assegnate ai vari campi di ricerca [am].

### Intelligenza artificiale applicata alla telecomunicazione
L'intelligenza artificiale è largamente utilizzata per la realizzazione di assistenti automatici online principalmente dalle compagnie telefoniche e di telecomunicazione, con l'intento di ridurre i costi di assunzione e formazione del personale [it].

### Intelligenza artificiale applicata alla robotica, all'automazione, al riconoscimento tramite Visione Artificiale, alla guida
Esempi:
- **Trasporti**: l'utilizzo dell'intelligenza artificiale infatti sta aumentando rapidamente per quanto concerne i trasporti sia di oggetti (es. droni di consegna) che di persone. Applicazioni della logica fuzzy sono state impiegate nella realizzazione di cambi di velocità per le automobili. Le automobili a guida autonoma sviluppate da [Google](/article/it/Google) e [Tesla](/article/it/Tesla) fanno largamente uso di tecniche di intelligenza artificiale [it].
- **Videosorveglianza**: l'intelligenza artificiale viene impiegata nel campo della videosorveglianza. Gli algoritmi consentono il riconoscimento degli oggetti presenti nella scena al fine di generare allarmi [it].

### Intelligenza artificiale applicata all'ambito video ludico
In ambito videogiochi l'applicazione dell'intelligenza artificiale sta facendo sempre più breccia, per migliorare i strumenti di sviluppo dei videogiochi, andando a impattare su ricambio del personale, con un maggiore impatto su artisti concettuali, i designer grafici, gli artisti dedicati al gioco finito e gli illustratori, in quanto l'intelligenza artificiale viene utilizzata per compiti come la generazione di storyboard, aspetto dei personaggi, rendering e animazioni e potrebbe contribuire fino al 50% dello sviluppo dei videogiochi entro il 2030-2035, inoltre a seconda dell'azienda si potrebbero usare soluzioni di intelligenza artificiale pubbliche o interne [it].

### Intelligenza artificiale conversazionale e in ambito sociale
Chatbot, assistenti vocali ([ChatGPT](/article/it/ChatGPT), [Alexa](/article/it/Amazon_Alexa), [Siri](/article/it/Siri), ecc.). L'applicazione di reti neurali complesse nella generazione di testi, o meglio, nella trasformazione di un input generalmente testuale in un output anch'esso espresso in caratteri, sta crescendo. In particolar modo negli ultimi anni, [OpenAI](/article/it/OpenAI) ha rilasciato numerose versioni del suo "modello" denominato [GPT](/article/it/GPT), il quale ha riscontrato notevole successo e scalpore. Attraverso questo modello basato su una particolare rete neurale, è stato possibile generare dei racconti, riassumere automaticamente dei testi, tradurre in maniera sempre più precisa da una lingua all'altra. Attraverso questa disciplina le applicazioni sono le più disparate, tra cui, degno di nota e a forte impatto sociale, quello riguardo al binomio giornalismo e scrittura. Il Washington Post ad esempio, già nel 2017 dichiarò di aver pubblicato in un anno 850 news elaborate da un'intelligenza artificiale. Il giornale canadese The Globe and Mail invece è interamente diretto da una intelligenza artificiale. Un altro utilizzo di questo modello trova riscontro nei tool di assistenza alla scrittura e generazione automatica di testi. A questo riguardo è nata a febbraio 2023 la prima collana di libri scritta interamente da un'intelligenza artificiale. La tecnologia è stata anche utilizzata per generare intere sceneggiature cinematografiche come per Il diario di Sisifo [it].

### AI generativa

All'inizio degli anni 2020, l'AI generativa ha guadagnato ampia popolarità. [ChatGPT](/article/it/ChatGPT), basato su GPT-3 e altri grandi modelli linguistici, è stato provato dal 14% degli adulti americani. I generatori di testo-immagine basati su AI come [Midjourney](/article/it/Midjourney), [DALL-E](/article/it/DALL-E) e [Stable Diffusion](/article/it/Stable_Diffusion) hanno comportato una crescente realismo e facilità d'uso, portando a una tendenza di foto generate da AI virali. Foto false che mostrano Papa Francesco in un cappotto bianco, l'arresto fittizio di Donald Trump e un attacco al Pentagono hanno attirato ampia attenzione, così come il loro uso nelle arti creative professionali [am].

### Applicazioni specifiche dell'industria

Esistono migliaia di applicazioni di AI di successo che servono a risolvere problemi specifici per particolari industrie o istituzioni. Un sondaggio del 2017 ha riportato che una su cinque aziende aveva "incorporato AI" in alcune delle loro offerte o processi [am].

In agricoltura, l'AI ha aiutato gli agricoltori a identificare le aree che necessitano di irrigazione, fertilizzanti, trattamenti antiparassitari o aumenti di rendimento. I professionisti agricoli utilizzano l'AI per condurre ricerca e sviluppo. L'AI è stata utilizzata per prevedere i tempi di maturazione di colture come i pomodori, monitorare l'umidità del suolo, costruire robot agricoli, condurre analisi predittive, classificare le chiamate emotive dei maiali, automatizzare le serre, identificare malattie e parassiti, e conservare l'acqua [am].

L'intelligenza artificiale serve nell'astronomia per analizzare i crescenti dati e applicazioni, principalmente per "classificare, regressione, clustering, predizione, generazione, scoperta e sviluppo di nuove intuizioni scientifiche", ad esempio per trovare esopianeti, prevedere l'attività solare e identificare segnali e risultati strumentali in astronomia delle onde gravitazionali. Può anche essere utilizzata per applicazioni spaziali come l'esplorazione dello spazio, l'analisi dei dati raccolti dalle missioni spaziali, decisioni scientifiche in tempo reale sui rover spaziali, il monitoraggio dei detriti spaziali e operazioni più autonome [am].

### Intelligenza artificiale nei giochi

I giochi sono stati utilizzati per mostrare e testare le tecniche di AI più avanzate dagli anni '50. [Deep Blue](/article/it/Deep_Blue) è diventato il primo programma di scacchi computerizzato a sconfiggere un campione del mondo di scacchi quando ha battuto Garry Kasparov l'11 maggio 1997. Nel 2011, in un'esibizione di Jeopardy!, il sistema di risposta alle domande di IBM, [Watson](/article/it/Watson_(computer)), ha sconfitto i due più grandi campioni di Jeopardy!, Brad Rutter e Ken Jennings, con un ampio margine. Nel marzo 2016, [AlphaGo](/article/it/AlphaGo) è diventato il primo sistema computerizzato per giocare a Go a sconfiggere senza handicap un giocatore professionista di Go quando ha battuto il campione di Go Lee Sedol in 4 delle 5 partite. Ha poi sconfitto Ke Jie nel 2017, che all'epoca era stato il numero 1 del mondo per due anni consecutivi [am].

Altri programmi gestiscono giochi di informazione imperfetta, come il poker, a livelli sovrumani con [Pluribus](/article/it/Pluribus_(computer)) e [Cepheus](/article/it/Cepheus_(computer)). [DeepMind](/article/it/DeepMind) ha creato un'"intelligenza artificiale generale" negli anni 2010 che poteva imparare da sola molti diversi giochi Atari [am].

### Intelligenza artificiale militare

Vari paesi stanno implementando applicazioni militari di AI. I principali programmi sottolineano comando e controllo, comunicazioni, sensori, fusione e integrazione. La ricerca si concentra sulla raccolta e l'analisi dell'intelligence, la logistica, le operazioni informatiche, le operazioni informative, e veicoli semi-autonomi e autonomi. Le tecnologie di AI consentono di coordinare sensori ed effettori, identificare e classificare minacce, contrassegnare posizioni nemiche, acquisire obiettivi, creare fuochi congiunti coordinati tra squadre umane e non umane di macchine da combattimento collegate in rete. L'AI è stata incorporata nelle operazioni militari in Iraq e Siria [am].

## Risvolti economici

Secondo l'Artificial Intelligence Index Report 2024 della Stanford University, nel 2023 il settore dell'intelligenza artificiale ha generato investimenti pari a 25,2 miliardi di dollari, quasi 9 volte superiori al 2022 e circa 30 rispetto al 2019 [it].

Nel 2023 l'Unione Europea investe nell'intelligenza artificiale una cifra dieci volte inferiore a quella degli Stati Uniti e pari alla metà di quella della Cina [it].

Il mercato italiano dell'intelligenza artificiale si presenta ancora agli albori, ma le prospettive per il futuro sono positive: nel 2018 ha raggiunto un valore di 85 milioni di euro, una cifra che fa riferimento agli investimenti nello sviluppo e nell'implementazione di progetti come [it]:

- sviluppo di algoritmi di intelligenza artificiale
- hardware per l'immagazzinamento e l'elaborazione di dati
- software per la gestione dei dati
- servizi di integrazione e personalizzazione

L'intelligenza artificiale si intreccia con altre tendenze digitali come la [Cloud Transformation](/article/it/Cloud_Transformation) e l'[Internet delle cose](/article/it/Internet_delle_cose). Il primo rende scalabile l'infrastruttura necessaria alla raccolta ed elaborazione dei dati, mentre il secondo crea dispositivi e sensori utili non solo per la raccolta dati ma anche per veicolare servizi basati sull'intelligenza artificiale [it].

In campo economico, particolarmente sensibile al cambiamento è il tasso di occupazione in generale, come nella tecnofinanza dove avviene la più profonda rivoluzione. L'utilizzo dell'intelligenza artificiale segue le regole del mercato, applicando però il [Paradosso di Jevons](/article/it/Paradosso_di_Jevons), ovvero: dove i miglioramenti tecnologici aumentano l'efficienza di una risorsa (es. uso efficiente dell'intelligenza artificiale e quello che ne consegue), aumenta anche il consumo della risorsa stessa (uso dell'intelligenza artificiale, risorse per sostenerla) anziché diminuirlo [it].

Vale a dire che più l'intelligenza artificiale si raffinerà e diventerà uno strumento prezioso, più la richiesta di mercato aumenterà. Quindi si andrà sistematicamente a ricercare metodi più economici di creazione di un'intelligenza artificiale, tanto che una persona capace di programmare potrebbe creare un'intelligenza artificiale personalizzata (non creata da terzi). Il paradosso di Jevons non è un reale paradosso: il termine fa capire che non è scontato che una risorsa sia illimitata, non etica, dannosa per il mercato, che finirebbe in una bolla economica o un'estrema settorializzazione. Il focus rimane sempre la maggiore efficienza del servizio, il quale si presume generebbe una maggiore domanda. Anche se l'andamento dei costi di utilizzo, anche in termine di risorse consumate, rimangono sempre da valutare. Un regime di monopolio non sussisterebbe nel mercato delle intelligenze artificiali. Data la moltitudine di bacini d'utenza, che riversano le loro molteplici e più svariate richieste, definire la curva d'utilità della domanda diventa labile, ma confrontabile con la capacità d'uso e facilità di consultazione di una data intelligenza artificiale [it].

### Il significato per le aziende

I media e le aziende stanno rivolgendo sempre più l'attenzione verso il tema dell'intelligenza artificiale, in quanto questa si sta dimostrando impattante in termini di efficientamento e automazione di software gestionali, processi industriali, e così via. Tecniche come l'anomaly detection consentono ad esempio di riconoscere, attraverso dati provenienti da sensori, oggetti che presentano dei difetti già in fase di produzione. Reti neurali in grado di stimare la postura umana sono uno strumento che può diventare fondamentale per salvaguardare, ad esempio, la corretta postura del corpo umano durante le ore lavorative, andando a migliorare la sicurezza sul lavoro. I modelli linguistici di grandi dimensioni, come ad esempio [GPT-4](/article/it/GPT-4), si stanno rivelando essere strumenti fondamentali per abbattere i tempi di sviluppo software, o ricevere risposte a domande su ostacoli incontrati nei processi lavorativi. Un capitolo a parte lo merita il mercato dell'audiovisivo, che attraverso i nuovi strumenti dell'AI, vede abbattersi drasticamente i tempi di produzione per film e serie, soprattutto in animazione [it].

### Disoccupazione

Secondo il report intitolato The Potentially Large Effects of Artificial Intelligence on Economic Growth, pubblicato da Goldman Sachs nel marzo 2023, l'intelligenza artificiale in particolare la sua capacità di generare contenuti senza l'intervento umano potranno garantire una crescita del 7% del PIL globale nei prossimi 10 anni. Tuttavia, essa è anche la causa prevedibile della perdita di 300 milioni di posti di lavoro nei settori amministrativo, legale, finanziario e bancario [it].

Secondo un rapporto del World Economic Forum del 2023, nei successivi 5 anni il 23% dei posti di lavoro a livello mondiale subirà dei mutamenti a causa dell'intelligenza artificiale. L'automazione sostituirà l'81% delle attività lavorative di intermediari di prestito, supervisori e impiegati d'ufficio [it].

Tuttavia, storicamente non sempre l'automazione è sinonimo di disoccupazione. Un precedente storico è rappresentato dall'introduzione del telaio meccanico che nel 1800 moltiplicò per 50 volte la produttività del lavoro, riducendo negli Stati Uniti il fabbisogno di manodopera del 98%. Eppure il crollo dei costi causò un'inaspettata esplosione della domanda, generando una quantità e varietà di posti di lavoro fino ad allora impensabile [it].

## Valutazione dell'intelligenza artificiale

Come determinare se un agente è intelligente o no? Nel 1950, Alan Turing propose una procedura generale per testare l'intelligenza di un agente, ora nota come test di Turing. Questa procedura permette di testare la maggior parte dei principali problemi dell'intelligenza artificiale. Tuttavia, è una sfida estremamente difficile attualmente e tutti gli agenti che l'hanno affrontata hanno fallito [ar].

L'intelligenza artificiale può anche essere valutata in base a problemi specifici come piccoli problemi di scacchi, riconoscimento della scrittura a mano e giochi. Questi test sono chiamati test di Turing esperti. Più piccolo è il problema, più obiettivi raggiungibili ci sono, e c'è un numero crescente di risultati positivi [ar].

I risultati dei test di intelligenza artificiale sono classificati nei seguenti gruppi [ar]:

- **Ottimale**: non è possibile una prestazione migliore.
- **Super-umano**: prestazione migliore di tutti gli esseri umani.
- **Umano elevato**: prestazione migliore della maggior parte degli esseri umani.
- **Sub-umano**: prestazione peggiore della maggior parte degli esseri umani.

Ad esempio, le prestazioni nel gioco della dama sono ottimali, le prestazioni negli scacchi rientrano nella categoria "umano elevato" e si avvicinano a "super-umano", e le prestazioni in molti compiti quotidiani svolti dagli esseri umani rientrano nella categoria "sub-umano" [ar].

Un approccio completamente diverso si basa sulla misurazione dell'intelligenza delle macchine attraverso test derivati da definizioni matematiche di intelligenza. Esempi di questo tipo di test sono iniziati alla fine degli anni '90, come i test di intelligenza che utilizzano i concetti di complessità e compressione di Andrey Kolmogorov. Marcus Hutter ha presentato definizioni simili di intelligenza delle macchine nel suo libro "Universal Artificial Intelligence" (Springer 2005), che è stato ulteriormente sviluppato da Legg e Hutter [ar].

I vantaggi delle definizioni matematiche sono che possono essere applicate all'intelligenza non umana, e in assenza di esaminatori umani [ar].

## Impatto ambientale

L'intelligenza artificiale richiede molta energia elettrica. Si stima che entro il 2027 richiederà tanta energia quanto un paese come i Paesi Bassi. Questo può aggravare notevolmente i problemi climatici [af].

Il 10 e l'11 febbraio 2025 si è svolto al Grand Palais di Parigi il Vertice internazionale sull'intelligenza artificiale, co-presieduto da Francia e India, nell'ambito del quale è stata sottoscritta una dichiarazione da 61 paesi; il documento, intitolato Statement on Inclusive and Sustainable Artificial Intelligence for People and the Planet, prevede la creazione di un'intelligenza artificiale aperta, inclusiva ed etica, nonché di un coordinamento è dialogo mondiale per prevenire un'eccessiva concentrazione di mercato. Il vertice ha sollevato per la prima volta il tema della sostenibilità ambientale dell'intelligenza artificiale e dei relativi costi energetici [it].

## Il futuro dell'intelligenza artificiale

Benché nel complesso non si ha ancora una visione omogenea sul tema, si individuano già aree di sviluppo particolarmente interessanti [it]:

- **Assistenti digitali**: si va dagli "altoparlanti intelligenti" agli assistenti personali integrati negli smartphone o dispositivi specifici e non sempre di successo (quali "AI Pin" o "Rabbit R1") tratta di assistenti vocali intelligenti in grado di gestire oggetti intelligenti presenti in casa o di assistere se non gestire le attività informatiche. Sono stati introdotti di recente, ma il loro mercato in Italia vale già 60 milioni di euro e il valore sembra destinato a crescere: in un futuro non troppo lontano, questi assistenti potrebbero fungere da canale con cui veicolare servizi e applicazioni legate al mondo dell'intelligenza artificiale, creando nuove opportunità di sviluppo per le aziende del settore [it].

- **Robot intelligenti**: a questa categoria appartengono i collaborative robot e gli AGV (Automated Guided Vehicle). I primi collaborano con un operatore umano e sono in grado di adattare il proprio comportamento agli stimoli esterni, mentre i secondi si adattano all'ambiente esterno muovendosi in autonomia, senza il supporto di guide fisiche o percorsi predeterminati [it].

- **Tutor Intelligenti**: a questa categoria appartengono gli avatar degli Edugames oppure dei robot che all'interno dei musei, e altri luoghi dell'apprendimento, guidano i discenti-visitatori e fungere dai docenti-educatori artificiali [it].

Una superintelligenza avanzata e la singolarità. Una superintelligenza è un ipotetico agente con un intelletto molto più brillante e capace del più brillante e dotato cervello umano. Lo studio dell'intelligenza artificiale generale potrebbe eventualmente portare a software sufficientemente intelligenti da potersi migliorare e perfezionare. Il software migliorato diventerebbe migliore nel migliorarsi, portando a ciò che I.J. Good chiamava "l'esplosione dell'intelligenza" e che Vernor Vinge chiamava la "singolarità". Tuttavia, le tecnologie non possono migliorare indefinitamente e tipicamente seguono una curva a forma di S, rallentando man mano che raggiungono i loro limiti fisici in termini di ciò che la tecnologia può fare [am].

## Il dibattito sull'intelligenza artificiale

Nel 2017 a seguito del convegno di esperti mondiali di intelligenza artificiale Conferenza di Asilomar sulla Intelligenza Artificiale Benefica, promosso dal [Future of Life Institute](/article/it/Future_of_Life_Institute), è stato redatto con amplissimo consenso un vademecum con 23 principi per affrontare le problematiche etiche, sociali, culturali e militari dell'Intelligenza Artificiale. Il documento è stato sottoscritto subito da oltre 800 esperti e in seguito da altre migliaia [it].

All'inizio del 2023 rappresentanti delle tre principali religioni abramitiche (cristianesimo, ebraismo e islam), di Microsoft e IBM, si sono incontrati in Vaticano alla Rome Call, per la richiesta congiunta di un'algoretica (la riflessione etica sull'uso degli algoritmi) che guidi la progettazione dell'intelligenza artificiale. Il 10 luglio 2024, nell'evento multi-religioso svoltosi nel Peace Memorial Park di Hiroshima, vari leader religiosi di 9 fedi orientali (es. buddismo, induismo, zoroastrismo, bahá'í) accompagnati dai leader delle religioni abramitiche, da figure di spicco del governo giapponese, della Microsoft, della IBM e della Cisco, firmano la Call for AI di Roma [it].

### Critiche e controversie

Una maggiore attenzione è rivolta alle implicazioni etiche, ambientali e sociali dell'intelligenza artificiale e alla necessità di aumentare la trasparenza e la responsabilità delle grandi aziende tecnologiche per i loro algoritmi. Le principali critiche si riferiscono a [it]:

- Pregiudizio algoritmico
- La mancanza di responsabilità per i risultati generati dagli algoritmi "black-box"
- Approvvigionamento non etico di minerali rari utilizzati nei dispositivi alimentati dall'intelligenza artificiale
- Impronta ambientale dei datacenter, il loro utilizzo di energia e acqua
- Sfruttamento del lavoro digitale "clickwork" coinvolto nell'etichettatura dei dati per allenamento di intelligenza artificiale e nella moderazione dei contenuti
- Manipolazione algoritmica delle preferenze di consumo e di voto degli utenti

### Trasparenza algoritmica e segreto industriale

Negli ultimi anni, a causa della crescente presenza di intelligenza artificiale nella società, ci sono stati dei tentativi di normare e integrare l'utilizzo delle intelligenze artificiali all'interno del quadro normativo europeo, con particolare attenzione al principio di trasparenza algoritmica, che può essere definito come "l'obbligo, gravante sui soggetti che adottano decisioni con l'ausilio di sistemi automatizzati di trattamento dei dati, di fornire ai destinatari una spiegazione comprensibile delle procedure utilizzate e di motivare sotto questo profilo le decisioni assunte". Il mancato rispetto della trasparenza violerebbe espressamente l'art. 111 della costituzione Italiana e il diritto alla difesa ex art. 24 della suddetta costituzione. Inoltre, è stata ribadita nel 2017, dalla Dichiarazione di Asilomar, l'esigenza di garantire la massima trasparenza in ambito di decisioni giudiziarie, in caso di coinvolgimento di sistemi autonomi [it].

### La responsabilità legale delle macchine a guida autonoma

Man man che le intelligenze artificiali acquistano autonomia, si fa sempre più pressante le necessità di chiarire su chi ricadono le conseguenze legali e non delle "scelte" che l'intelligenza artificiale è portata ad attuare; spesso necessariamente, o durante una richiesta dell'utente o comunque nel corso del conseguimento della propria funzione (in base ai dati in cui è stata educata o informata). Vi possono essere casi ed eventi del mondo reale nei quali l'intelligenza artificiale non sa come agire, specialmente in determinate situazioni che richiedono scelta immediata, questo magari poiché non educata ad una scelta in tale ambito o perché i programmatori non sapevano nemmeno loro "cosa era meglio". Un esempio calzante di questo lo si vede nelle vetture autonome, dove la macchina deve portare i passeggeri (o merci) da un punto ad un altro, senza sapere tutti i possibili ostacoli che incontrerà nel suo cammino. Si educa quindi per probabilità dell'avverarsi delle situazioni, cercando di prevedere ogni scenario possibile. Una macchina a guida autonoma deve sapere prendere azioni che massimizzano la sopravvivenza dei suoi passeggeri ma anche degli utenti terzi che usano la strada [it].

Questi dilemmi etici legati alla scelta, così come il classico [dilemma ferroviario](/article/it/dilemma_ferroviario), applicato alle Intelligenze Artificiali possono essere visti come un ante segnale della problematica di gestione dati nei sistemi complessi [it].

### L'intelligenza artificiale e le scienze umane

Rispondere alla domanda "Può una macchina pensare?" "la macchina è inanimata?" è dibattito tuttora aperto a causa di argomentazioni a favore (Daniel Dennett, Hilary Putnam, Roger Penrose) e contro (Hubert Dreyfus, John Searle, Gerald Edelman, Jerry Fodor). Alcuni studiosi ritengono che il connubio intelligenza artificiale-intelligenza umana possa dar luogo ad un nuovo sistema cognitivo di tipo 0, affiancando ai sistemi cognitivi 1 e 2 teorizzati da [Daniel Kahneman](/article/it/Daniel_Kahneman) [it].

### Impatto psicologico

L'impatto psicologico, specialmente in soggetti a rischio, nell'uso continuo e reiterato della sola intelligenza artificiale, preferendo essa all'interazione sociale, è in fase di analisi e monitoraggio. L'uso massivo dell'intelligenza artificiale potrebbe ridurre le preferenze interattive in individui sensibili, preferendo l'interazione artificiale all'opportunità di interazione umana, che se non adeguatamente tratta potrebbe portare ad una "atrofizzazione" dalle abilità sociali. Gli individui potrebbero percepire più rischioso, per il loro benessere psicologico, sviluppare e mantenere le competenze sociali, quali la comunicazione empatica e il confronto diretto [it].

Alcune correnti di pensiero sono preoccupate riguardo la neutralità e qualità dell'informazioni di ritorno, in quanto non è ancora del tutto ben consolidata e chiara l'imparzialità delle informazioni di output di alcune intelligenze artificiali [it].

## Intelligenza artificiale nella fantascienza

Nelle opere di fantascienza l'intelligenza artificiale è un tema ricorrente, come semplice elemento narrativo o come argomento centrale della storia. Generalmente è presentata sotto forma di computer avanzati, robot o androidi. Il tema è spesso legato a quello classico della [ribellione della macchina](/article/it/ribellione_della_macchina), in cui un computer (nella maggior parte dei casi senziente) si rivolta contro gli esseri umani che l'avevano costruito [it].

Tra i computer senzienti rientrano ad esempio [Multivac](/article/it/Multivac), presente in alcuni racconti di [Isaac Asimov](/article/it/Isaac_Asimov), paragonabile ai moderni sistemi di grid computing, e [HAL 9000](/article/it/HAL_9000) del film [2001: Odissea nello spazio](/article/it/2001:_Odissea_nello_spazio) (1968) di [Stanley Kubrick](/article/it/Stanley_Kubrick). Invece [Pensiero Profondo](/article/it/Pensiero_Profondo), nella [Guida galattica per autostoppisti](/article/it/Guida_galattica_per_autostoppisti), è un'intelligenza artificiale capace di fornire la risposta alla "domanda fondamentale sulla vita, l'universo e tutto quanto". Nella serie cinematografica di [Terminator](/article/it/Terminator), il supercomputer [Skynet](/article/it/Skynet) è presentato come un evolutissimo insieme di network che, costruiti dal Dipartimento della difesa degli Stati Uniti verso la fine della guerra fredda, finiranno per divenire un insieme autocosciente e intraprendere, al comando di un esercito di robot e cyborg, una spietata guerra per lo sterminio della specie umana. Nel film [Matrix](/article/it/Matrix) le macchine intelligenti tengono in schiavitù miliardi di esseri umani, per trarre da essi energia elettrica [it].

I robot o androidi senzienti sono anch'essi un classico. Nell'ipotesi che le macchine possano man mano diventare più simili agli esseri umani, gli autori hanno ipotizzato macchine con enorme capacità di calcolo e dotate di personalità. I "robot positronici" come il robot [R. Daneel Olivaw](/article/it/R._Daneel_Olivaw) del romanzo [Fondazione](/article/it/Fondazione_(romanzo)), [Marvin](/article/it/Marvin_l'androide_paranoico) l'androide paranoico, [R2-D2](/article/it/R2-D2) e [C-3PO](/article/it/C-3PO) di [Guerre stellari](/article/it/Guerre_stellari), [Data](/article/it/Data_(personaggio)) di [Star Trek: The Next Generation](/article/it/Star_Trek:_The_Next_Generation) e [Chappie](/article/it/Chappie) di [Humandroid](/article/it/Humandroid) sono solo alcuni esempi tra i più noti. Queste macchine si distinguono dai semplici robot per una personalità spiccata e "umanizzata", resa possibile da un'intelligenza artificiale estremamente evoluta [it].

Ne [Il grande ritratto](/article/it/Il_grande_ritratto) di [Dino Buzzati](/article/it/Dino_Buzzati) del 1960 s'immagina un'intelligenza artificiale grande come una città e in grado di manipolare gli esseri umani. In ambito musicale, band italiane come i [Calibro 35](/article/it/Calibro_35) e gli [Eterea Post Bong Band](/article/it/Eterea_Post_Bong_Band) hanno creato dischi concept sul tema, facendo rappare un'intelligenza artificiale o parlando dell'evoluzione del rapporto uomo-macchina [it].

Oltre al mondo del cinema, anche la televisione, i cartoni animati, i fumetti e i videogiochi hanno sfruttato in modo massiccio il tema dell'intelligenza artificiale [it].

## Regolamentazione

### G7

Il 30 ottobre 2023 i membri del G7 nel contesto del Processo di Hiroshima, sottoscrivono undici principi guida per la progettazione, produzione e implementazione di sistemi di intelligenza artificiale avanzati. Su contributo ispiratore dell'OCSE, raggiungono un accordo sui principi guida internazionali per gli sviluppatori di intelligenza artificiale e stilano il Codice di condotta volontario internazionale per i sistemi avanzati di Intelligenza Artificiale un codice di condotta volontario per gli sviluppatori dell'intelligenza artificiale [it].

### Unione europea

#### Codice etico UE per l'intelligenza artificiale

Partendo dalla premessa per cui i governi devono garantire l'impiego dell'intelligenza artificiale nel massimo rispetto dell'etica, nell'aprile del 2019, l'[Unione Europea](/article/it/Unione_Europea) ha elaborato il suo codice etico, che contiene le linee guida su utilizzo e sviluppo di sistemi di intelligenza artificiale. Il documento, che è stato predisposto da un gruppo di 52 esperti, rappresentati da informatici, ingegneri ma anche giuristi, filosofi, industriali, matematici, ha avuto un iter lungo e varie fasi di approfondimento [it].

Il punto di partenza dell'intero documento, e di tutti i principi giuridici che ne sono scaturiti, è che l'intelligenza artificiale deve avere l'uomo al centro e deve essere al servizio del bene comune per migliorare il benessere e garantire la libertà. Per prima cosa, il gruppo di esperti ha identificato le fondamenta giuridiche sulle quali il codice dovesse poggiare ricercandole nei Trattati UE, nella Carta dei Diritti e nella legge internazionale dei Diritti Umani. Da questa analisi sono stati individuati quei diritti inderogabili che, nell'Unione Europea, devono essere rispettati per l'intelligenza artificiale, vale a dire [it]:

- Rispetto per la dignità dell'uomo
- Libertà dell'individuo
- Rispetto per la democrazia e per la giustizia
- Eguaglianza e non discriminazione
- Diritti dei cittadini

A questo punto è stato possibile dare indicazioni su quali fossero i principi etici da seguire nell'Unione per garantire che i sistemi di intelligenza artificiale siano sfruttati in modo affidabile, ovvero rispetto per l'autonomia dell'uomo, prevenzione del danno, equità e correttezza [it].

L'ultima fase di lavoro del gruppo di esperti è stata quella di redigere le linee guida UE del codice etico cui aziende, ricercatori e le comunità in generale dovranno attenersi e che rappresentano la traduzione operativa e la sintesi dei diritti fondamentali e dei principi sopra elencati [it].

#### Linee guida

1. **Supervisione umana**: l'intelligenza artificiale deve essere al servizio dell'uomo e non deve invece ridurne, limitarne o fuorviarne l'autonomia; inoltre, non devono essere sviluppati sistemi che mettano a rischio i diritti fondamentali dell'uomo. La persona deve restare autonoma e in grado di supervisionare il sistema stesso [it].

2. **Solidità tecnica e sicurezza**: gli algoritmi devono essere affidabili e sviluppati in modo tale che la sicurezza non venga messa in pericolo durante l'intero ciclo di vita del sistema [it].

3. **Privacy e governance dei dati**: i cittadini devono sempre essere informati dell'utilizzo dei propri dati personali nel massimo rispetto della normativa UE sulla privacy per l'intero ciclo di vita del sistema che fa uso dell'intelligenza artificiale [it].

4. **Trasparenza**: significa tracciabilità dei sistemi di intelligenza artificiale. Tutti i dati utilizzati, inclusi gli algoritmi, vanno documentati; solo così si potranno capire i motivi per cui, ad esempio, una decisione basata sull'intelligenza artificiale è stata presa in modo errato [it].

5. **Diversità, assenza di discriminazione, correttezza**: i sistemi di intelligenza artificiale devono prendere in considerazione tutte le capacità e le abilità umane, garantendo l'accessibilità a tutti [it].

6. **Benessere sociale e ambientale**: i sistemi di intelligenza artificiale devono essere utilizzati per sostenere cambiamenti ambientali positivi e perseguire obiettivi di sviluppo sostenibile [it].

7. **Responsabilità**: devono essere adottati meccanismi di responsabilità nel riportare i dati e gli algoritmi utilizzati nei sistemi di intelligenza artificiale. Questo processo di valutazione consente di minimizzare eventuali impatti negativi [it].

#### Artificial Intelligence Act

Il 21 maggio 2024 il Consiglio dell'Unione europea ha approvato un apposito regolamento noto anche come [Legge sull'intelligenza artificiale](/article/it/Legge_sull'intelligenza_artificiale), che mira ad introdurre un quadro normativo e giuridico comune classificando e regolamentando le applicazioni dell'intelligenza artificiale in base al rischio di causare danni ai cittadini. Questa classificazione rientra principalmente in tre categorie: pratiche vietate, sistemi ad alto rischio e altri sistemi [it].

Le pratiche vietate sono quelle che impiegano l'intelligenza artificiale per provocare manipolazioni subliminali o sfruttare le vulnerabilità delle persone che possono provocare danni fisici o psicologici, per fare un uso indiscriminato dell'identificazione biometrica remota in tempo reale negli spazi pubblici ad opera delle forze dell'ordine o per utilizzare "punteggi sociali" derivati dall'intelligenza artificiale da parte delle autorità per colpire ingiustamente individui o gruppi. Il regolamento vieterebbe completamente questi ultimi, mentre per i primi tre viene proposto un regime di autorizzazione [it].

I sistemi ad alto rischio, secondo il regolamento proposto, sono quelli che pongono minacce significative alla salute, alla sicurezza o ai diritti fondamentali delle persone. Richiedono una valutazione di conformità obbligatoria, intrapresa come autovalutazione da parte del fornitore, prima di essere immessi sul mercato. Applicazioni particolarmente critiche, come quelle per i dispositivi medici, richiedono che l'autovalutazione del fornitore ai sensi del regolamento sull'intelligenza artificiale venga presa in considerazione dall'organismo notificato che conduce la valutazione ai sensi delle normative dell'Unione Europea esistenti, come il regolamento sui dispositivi medici [it].

La legge propone inoltre l'introduzione di un Comitato Europeo per l'intelligenza artificiale per promuovere la cooperazione internazionale e garantire il rispetto del regolamento [it].

### In Italia

Nel 2023, l'Autorità garante per la protezione dei dati personali ha approvato un regolamento che prevede tre principi per le decisioni terapeutiche assunte da sistemi automatizzati: trasparenza dei processi decisionali, supervisione umane delle decisioni automatizzate e non discriminazione algoritmica [it].

### Svizzera

Nel 2023 l'incaricato federale della protezione dei dati e della trasparenza (IFPDT) ha ribadito in forma scritta che la legge sulla protezione dei dati si applica anche all'intelligenza artificiale [it].

### Stati Uniti d'America

Nel marzo 2023 Google ha proposto un'agenda digitale per la definizione di un'intelligenza responsabile, che prevede fra l'altro il rispetto delle normative vigenti in tema di privacy e sicurezza informatica [it].

Nel maggio 2023 il vice presidente di Microsoft Brad Smith ha chiesto di firmare un ordine esecutivo che obblighi tutte le società informatiche statunitensi ad adottare gli standard del National Institute of Standards and Technology (NIST), che è incaricato di analizzare i loro rapporti annuali. La regolamentazione prevede l'obbligo di arrestare l'intelligenza artificiale nei casi di emergenza [it].

Nel luglio 2023 l'amministrazione di Joe Biden e le maggiori aziende informatiche del settore (tra cui Alphabet, Microsoft, Meta, Anthropic e OpenAI) raggiungono un accordo che prevede una serie di regole alle quali single operatori sono liberi da aderire su base volontaria, in attesa dell'approvazione di una regolamentazione vincolante da parte del Congresso USA [it].

Uno dei primi punti che le aziende di settore si sono dette pronte a introdurre è quello relativo alle filigrane che dovrebbero identificare inequivocabilmente testo, video, audio e immagini generate dall'Intelligenza Artificiale [it].

Nel luglio 2023 Anthropic, Google, Microsoft e OpenAI hanno dato vita al Frontier Model Forum. A partire dal 2024 lo sviluppo della intelligenza artificiale è stato indirizzato alla mitigazione e all'adattamento ai cambiamenti climatici, alla diagnosi precoce e la prevenzione del cancro. Secondo il presidente di Microsoft Brad Smith, le aziende produttrici di modelli di frontiera hanno il compito di garantire che questa tecnologia "sia sicura, protetta e rimanga sotto il controllo umano" [it].

Il 30 ottobre 2023 il presidente Biden firma un ordine esecutivo che obbliga gli sviluppatori dell'intelligenza artificiale a condividere i propri test di sicurezza con il governo prima di rendere pubblici i loro software [it].

Il National Institute of Standards and Technology stabilisce lo standard per lo svolgimento di questi test di sicurezza. il dipartimento per il commercio sviluppa le linee guida e la filigrana per l'autenticazione dei contenuti generati con l'intelligenza artificiale che trova impiego "nelle sentenze, nella libertà condizionale e nella libertà vigilata, nella scarcerazione e nella detenzione preventiva, nelle valutazioni dei rischi, nella sorveglianza, nella previsione del crimine, nella polizia predittiva e nell'analisi forense" [it].

## Vedi anche

- [Auto-GPT](/article/it/Auto-GPT)
- [Deepfake](/article/it/Deepfake)
- [ChatGPT](/article/it/ChatGPT)
- [Partenariato Globale sull'Intelligenza Artificiale](/article/it/Partenariato_Globale_sull'Intelligenza_Artificiale)
- [Calcolo quantistico](/article/it/Calcolo_quantistico)
- [Intelligenza artificiale generale](/article/it/Intelligenza_artificiale_generale)
- [Sicurezza dell'intelligenza artificiale](/article/it/Sicurezza_dell'intelligenza_artificiale)
- [LaMDA](/article/it/LaMDA)
- [The Stargate Project](/article/it/The_Stargate_Project)
- [Problema del controllo dell'intelligenza artificiale](/article/it/Problema_del_controllo_dell'intelligenza_artificiale)
- [Legge dell'intelligenza artificiale](/article/it/Legge_dell'intelligenza_artificiale)
- [Automazione dei processi aziendali](/article/it/Automazione_dei_processi_aziendali)
- [Automazione robotica dei processi](/article/it/Automazione_robotica_dei_processi)
- [Pensiero computazionale](/article/it/Pensiero_computazionale)
- [Regolamentazione dell'intelligenza artificiale](/article/it/Regolamentazione_dell'intelligenza_artificiale)
- [Intelligenza artificiale debole](/article/it/Intelligenza_artificiale_debole)
- [Salario di base](/article/it/Salario_di_base)
- [Corsa agli armamenti dell'intelligenza artificiale](/article/it/Corsa_agli_armamenti_dell'intelligenza_artificiale)
- [Controllo dell'intelligenza artificiale](/article/it/Controllo_dell'intelligenza_artificiale)
- [Logica basata su casi](/article/it/Logica_basata_su_casi)
- [Reddito di base universale](/article/it/Reddito_di_base_universale)
- [Etica dell'intelligenza artificiale](/article/it/Etica_dell'intelligenza_artificiale)